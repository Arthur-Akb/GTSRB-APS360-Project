{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18f68af9e91a49acaa541f0463cfb36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b02e126338c94e878d321e40b1ab59f2",
              "IPY_MODEL_cdf41bca3ff240d38877b2cb9565d83e",
              "IPY_MODEL_602e33f8c1974c14a991bcae0820f714"
            ],
            "layout": "IPY_MODEL_8f91ea6e3e5b41bc85c6674d55184940"
          }
        },
        "b02e126338c94e878d321e40b1ab59f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0b82a851a2649db891e5bd1484d9036",
            "placeholder": "​",
            "style": "IPY_MODEL_7dd0618027874d5f8ed7d0eed465ea25",
            "value": "100%"
          }
        },
        "cdf41bca3ff240d38877b2cb9565d83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ad2cc7cebaa4a2a85b89bd27849a7cb",
            "max": 88978620,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c634bdc5c5f496f89d6b609768f5018",
            "value": 88978620
          }
        },
        "602e33f8c1974c14a991bcae0820f714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d9f8f8c83f74fba85d4ee0987a7d82b",
            "placeholder": "​",
            "style": "IPY_MODEL_e346e1c00a0a4710a10ed08c4881597b",
            "value": " 88978620/88978620 [00:06&lt;00:00, 18041690.06it/s]"
          }
        },
        "8f91ea6e3e5b41bc85c6674d55184940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0b82a851a2649db891e5bd1484d9036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd0618027874d5f8ed7d0eed465ea25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ad2cc7cebaa4a2a85b89bd27849a7cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c634bdc5c5f496f89d6b609768f5018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d9f8f8c83f74fba85d4ee0987a7d82b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e346e1c00a0a4710a10ed08c4881597b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "445ebcf804a74521a6f0a5283e7d9620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c901038e6ac841008ba3797790fc70d1",
              "IPY_MODEL_788fa265440e4209b8b934fa8fe3004c",
              "IPY_MODEL_63519c35742a4300afbf88ad43b15d58"
            ],
            "layout": "IPY_MODEL_594f7b85bd614bdb93fecc85bbf03b8f"
          }
        },
        "c901038e6ac841008ba3797790fc70d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c21754109c55485ab7fd0b2d434ec80a",
            "placeholder": "​",
            "style": "IPY_MODEL_c6e3531f4bde41bda2b4fbe9fb40c4d9",
            "value": "100%"
          }
        },
        "788fa265440e4209b8b934fa8fe3004c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2b06654ce814555815815f53eb3d8b9",
            "max": 99620,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_155f231b8c7c4e138a7ae722acd465a7",
            "value": 99620
          }
        },
        "63519c35742a4300afbf88ad43b15d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57a0150aa803494e895688a88b448327",
            "placeholder": "​",
            "style": "IPY_MODEL_c97c1afc49724b1a9f0efc18c49d8069",
            "value": " 99620/99620 [00:00&lt;00:00, 217943.02it/s]"
          }
        },
        "594f7b85bd614bdb93fecc85bbf03b8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c21754109c55485ab7fd0b2d434ec80a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6e3531f4bde41bda2b4fbe9fb40c4d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2b06654ce814555815815f53eb3d8b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "155f231b8c7c4e138a7ae722acd465a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57a0150aa803494e895688a88b448327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c97c1afc49724b1a9f0efc18c49d8069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katL7/GTSRB-APS360/blob/CNN-from-scratch-is-working/APS360_Traffic_Sign_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "FwK5G34Jx_Ez"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KcORCBgQ_2zK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from google.colab import drive\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google drive"
      ],
      "metadata": {
        "id": "VqeZZwuRFtO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b0H3ePoFvPo",
        "outputId": "749e24e7-a5f3-4d6e-d1af-af495f4105b2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "Bamt_XDHyJyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split into training, validation and test - stratify each\n",
        "def get_val_test(batch_size=64, img_size=50):\n",
        "    # Rescale images to all be the same size\n",
        "    data_transform = transforms.Compose([transforms.Resize((img_size,img_size)), \n",
        "                                         transforms.ToTensor()])\n",
        "\n",
        "    # Get paths to data in folder\n",
        "    data = datasets.GTSRB('data', download=True, split='test',\n",
        "                           transform=data_transform)\n",
        "\n",
        "    class_idxs = {}\n",
        "    #Loop through filenames and sort into classes\n",
        "    for i, data in enumerate(data):\n",
        "        img, label = data\n",
        "        if label in class_idxs:\n",
        "          class_idxs[label].append(i)\n",
        "        else:\n",
        "          class_idxs[label] = [i]\n",
        "\n",
        "    np.random.seed(1000)\n",
        "    test_indices = []\n",
        "    val_indices = []\n",
        "\n",
        "    for class_key in class_idxs:\n",
        "      #Split validation/testing indices as 0.7/0.3 split by class\n",
        "      np.random.shuffle(class_idxs[class_key])\n",
        "      split = int(len(class_idxs[class_key]) * 0.7)\n",
        "      val_indices += class_idxs[class_key][:split]\n",
        "      test_indices += class_idxs[class_key][split:]\n",
        "\n",
        "    #Shuffle the testing/validation indices\n",
        "    np.random.shuffle(test_indices)\n",
        "    np.random.shuffle(val_indices)\n",
        "\n",
        "    #testing data loader\n",
        "    test_sampler = SubsetRandomSampler(test_indices)\n",
        "    test_loader = torch.utils.data.DataLoader(data, batch_size=batch_size,\n",
        "          num_workers=0, sampler=test_sampler)\n",
        "\n",
        "    #Validation data loader\n",
        "    val_sampler = SubsetRandomSampler(val_indices)\n",
        "    val_loader = torch.utils.data.DataLoader(data, batch_size=batch_size,\n",
        "          num_workers=0, sampler=val_sampler)\n",
        "    \n",
        "    return val_loader, test_loader"
      ],
      "metadata": {
        "id": "8e1zsJIX1uKP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_data_loader(batch_size=64, img_size=50):\n",
        "    # Rescale images to all be the same size\n",
        "    data_transform = transforms.Compose([transforms.Resize((img_size,img_size)), \n",
        "                                         transforms.ToTensor()])\n",
        "\n",
        "    # Get paths to data in folder\n",
        "    data = datasets.GTSRB('data', download=True, split=\"train\",\n",
        "                          transform=data_transform)\n",
        "  \n",
        "    np.random.seed(1000)\n",
        "    #test data loader\n",
        "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size,\n",
        "          num_workers=0, shuffle=True)\n",
        "    \n",
        "    return train_loader\n",
        "\n"
      ],
      "metadata": {
        "id": "cJ4zLm18CYVS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader, test_loader = get_val_test(64)"
      ],
      "metadata": {
        "id": "_u0ZknId8qib"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_loader = get_train_data_loader(64)"
      ],
      "metadata": {
        "id": "KXXC8d37DfG4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the model using transfer learning"
      ],
      "metadata": {
        "id": "wzJ5yVksa_T1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First I'm gonna try my own CNN since AlexNet was trained on 224x224 and our images are a lot smaller (not sure if this matters)"
      ],
      "metadata": {
        "id": "y-F6G81ld7Ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrafficSignModel(nn.Module):\n",
        "  def __init__(self):\n",
        "     super(TrafficSignModel, self).__init__()\n",
        "     self.name = \"TrafficSignModel\"\n",
        "     self.conv1 = nn.Conv2d(3, 5, 5) # 3 input channels, 5 output channels, kernel size of 5\n",
        "     self.pool = nn.MaxPool2d(2, 2) # kernel size of 2, stride of 2\n",
        "     self.conv2 = nn.Conv2d(5, 10, 5) # 5 input channels, 10 output channels, kernel size of 5\n",
        "     self.fc1 = nn.Linear(10 * 9 * 9, 28) # 10 input channels, 12*12 input dimension, output to 28 channels\n",
        "     self.fc2 = nn.Linear(28, 43) # 28 channels to 43 channels for classification\n",
        "         \n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 10 * 9 * 9) # Flatten image\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    x = x.squeeze(1) # Flatten to [batch_size]\n",
        "    return x"
      ],
      "metadata": {
        "id": "ddDR2-8gbFQO"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the network"
      ],
      "metadata": {
        "id": "P1nKIQ3sj3Gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Overview\n",
        "classes = { 0:'Speed limit (20km/h)',\n",
        "            1:'Speed limit (30km/h)', \n",
        "            2:'Speed limit (50km/h)', \n",
        "            3:'Speed limit (60km/h)', \n",
        "            4:'Speed limit (70km/h)', \n",
        "            5:'Speed limit (80km/h)', \n",
        "            6:'End of speed limit (80km/h)', \n",
        "            7:'Speed limit (100km/h)', \n",
        "            8:'Speed limit (120km/h)', \n",
        "            9:'No passing', \n",
        "            10:'No passing veh over 3.5 tons', \n",
        "            11:'Right-of-way at intersection', \n",
        "            12:'Priority road', \n",
        "            13:'Yield', \n",
        "            14:'Stop', \n",
        "            15:'No vehicles', \n",
        "            16:'Veh > 3.5 tons prohibited', \n",
        "            17:'No entry', \n",
        "            18:'General caution', \n",
        "            19:'Dangerous curve left', \n",
        "            20:'Dangerous curve right', \n",
        "            21:'Double curve', \n",
        "            22:'Bumpy road', \n",
        "            23:'Slippery road', \n",
        "            24:'Road narrows on the right', \n",
        "            25:'Road work', \n",
        "            26:'Traffic signals', \n",
        "            27:'Pedestrians', \n",
        "            28:'Children crossing', \n",
        "            29:'Bicycles crossing', \n",
        "            30:'Beware of ice/snow',\n",
        "            31:'Wild animals crossing', \n",
        "            32:'End speed + passing limits', \n",
        "            33:'Turn right ahead', \n",
        "            34:'Turn left ahead', \n",
        "            35:'Ahead only', \n",
        "            36:'Go straight or right', \n",
        "            37:'Go straight or left', \n",
        "            38:'Keep right', \n",
        "            39:'Keep left', \n",
        "            40:'Roundabout mandatory', \n",
        "            41:'End of no passing', \n",
        "            42:'End no passing veh > 3.5 tons' }"
      ],
      "metadata": {
        "id": "tXX00XOmkLPq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to obtain accuracy\n",
        "def get_accuracy(net, data_loader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for imgs, labels in data_loader:\n",
        "    output = net(imgs)\n",
        "    prediction = output.max(1, keepdim=True)[1]\n",
        "    correct += prediction.eq(labels.view_as(prediction)).sum().item()\n",
        "    total += imgs.shape[0]\n",
        "  return correct / total"
      ],
      "metadata": {
        "id": "F5r5Pur9m5Jw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to obtain error\n",
        "def get_error(net, data_loader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  evaluate_net = net.eval()\n",
        "\n",
        "  for imgs, labels in data_loader:\n",
        "    output = evaluate_net(imgs)\n",
        "    prediction = output.max(1, keepdim=True)[1]\n",
        "    correct += prediction.eq(labels.view_as(prediction)).sum().item()\n",
        "    total += imgs.shape[0]\n",
        "  return (total - correct) / total"
      ],
      "metadata": {
        "id": "I8Yh0Fs51Y-z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to obtain loss\n",
        "def get_loss(net, data_loader, criterion):\n",
        "  loss = 0.0\n",
        "  total_loss = 0.0\n",
        "  evaluate_net = net.eval()\n",
        "  for imgs, labels in data_loader:\n",
        "    output = evaluate_net(imgs)\n",
        "    loss = criterion(output, labels)\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  loss = float(total_loss) / (len(data_loader))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "h1CAN_2B2BPt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get model name\n",
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch)\n",
        "    return path"
      ],
      "metadata": {
        "id": "an92DWly4Fbn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot Training Curve\n",
        "def plot_training_curve(path):\n",
        "    \"\"\" Plots the training curve for a model run, given the csv files\n",
        "    containing the train/validation error/loss.\n",
        "\n",
        "    Args:\n",
        "        path: The base path of the csv files produced during training\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    train_err = np.loadtxt(\"{}_train_err.csv\".format(path))\n",
        "    val_err = np.loadtxt(\"{}_val_err.csv\".format(path))\n",
        "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
        "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
        "    plt.title(\"Train vs Validation Error\")\n",
        "    n = len(train_err) # number of epochs\n",
        "    plt.plot(range(1,n+1), train_err, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_err, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Error\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    plt.title(\"Train vs Validation Loss\")\n",
        "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "de6ENbpS5sTJ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_net(net, train_loader, val_loader, batch_size=64, learning_rate=0.01, num_epochs=30):\n",
        "  # Set the seed for reproducible results\n",
        "  torch.manual_seed(1000)\n",
        "\n",
        "  # Define the loss function - we will use Cross Entropy Loss for this classification problem\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  # Define the optimizer -  we will use Adaptive moment estimation\n",
        "  optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
        "\n",
        "  # Arrays to store stats\n",
        "  train_err = np.zeros(num_epochs)\n",
        "  train_loss = np.zeros(num_epochs)\n",
        "  val_err = np.zeros(num_epochs)\n",
        "  val_loss = np.zeros(num_epochs)\n",
        "\n",
        "  n = 0 # number iterations\n",
        "  for epoch in range(num_epochs):\n",
        "    total_train_loss = 0.0\n",
        "    for imgs, labels in train_loader:\n",
        "     # print(imgs)\n",
        "     # print(type(imgs))\n",
        "      out = net(imgs)                 # forward passs\n",
        "      loss = criterion(out, labels)   # compute loss\n",
        "      loss.backward()                 # backward pass\n",
        "      optimizer.step()                # update paramters\n",
        "      optimizer.zero_grad()           # clean up\n",
        "\n",
        "      total_train_loss += loss.item()\n",
        "\n",
        "    train_err[epoch] = get_error(net, train_loader)\n",
        "    train_loss[epoch] = float(total_train_loss) / (len(train_loader))\n",
        "    val_err[epoch] = get_error(net, val_loader)\n",
        "    val_loss[epoch] = get_loss(net, val_loader, criterion)\n",
        "\n",
        "    print((\"Epoch {}: Train error: {}, Train loss: {}, Val error: {}, Val loss: {}\").format(\n",
        "        epoch +1,\n",
        "        train_err[epoch],\n",
        "        train_loss[epoch],\n",
        "        val_err[epoch],\n",
        "        val_loss[epoch]))\n",
        "    \n",
        "    # Save the current model after each epoch\n",
        "    model_path = get_model_name(net.name, batch_size, learning_rate, epoch)\n",
        "    torch.save(net.state_dict(), model_path)\n",
        "\n",
        "  # Finished training, save statistics to CSV\n",
        "  epochs = np.arange(1, num_epochs + 1)\n",
        "  np.savetxt(\"{}_train_err.csv\".format(model_path), train_err)\n",
        "  np.savetxt(\"{}_train_loss.csv\".format(model_path), val_err)\n",
        "  np.savetxt(\"{}_val_err.csv\".format(model_path), val_err)\n",
        "  np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss)\n",
        "\n",
        "  # plotting\n",
        "  plot_training_curve(model_path)\n"
      ],
      "metadata": {
        "id": "yat0s7Q-j4kU"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to overfit the data"
      ],
      "metadata": {
        "id": "6uM24qE2sBI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_debug_loader():\n",
        "  # Rescale images to all be the same size\n",
        "\n",
        "  data_transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Resize((50,50))])\n",
        "    \n",
        "  # Get paths to data in folder\n",
        "  debug_data = datasets.GTSRB('data', download=True, split=\"train\",\n",
        "                        transform=data_transform)\n",
        "  #print(type(debug_data))\n",
        "  #debug_data = list(debug_data)\n",
        "  #debug_data = debug_data[:64]\n",
        "  #print(type(debug_data))\n",
        "\n",
        "  np.random.seed(1000)\n",
        "  indices = np.arange(len(debug_data))\n",
        "  np.random.shuffle(indices)\n",
        "  debug_sampler = SubsetRandomSampler(indices[:64])\n",
        "\n",
        "  debug_loader = torch.utils.data.DataLoader(debug_data, batch_size=64,\n",
        "        num_workers=0, sampler=debug_sampler)\n",
        "  return debug_loader\n"
      ],
      "metadata": {
        "id": "kyG-_XD0sDVJ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overfit_loader = get_debug_loader()\n",
        "model = TrafficSignModel()\n",
        "train_net(model, overfit_loader, overfit_loader, batch_size=64, learning_rate=0.01, num_epochs=30)"
      ],
      "metadata": {
        "id": "DQVFjMfJy1Pw",
        "outputId": "14bc1d58-49b2-459f-e97f-647112cd6b32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train error: 0.953125, Train loss: 3.7591512203216553, Val error: 0.953125, Val loss: 3.708005428314209\n",
            "Epoch 2: Train error: 0.953125, Train loss: 3.708005428314209, Val error: 0.953125, Val loss: 3.6142754554748535\n",
            "Epoch 3: Train error: 0.9375, Train loss: 3.6142752170562744, Val error: 0.9375, Val loss: 3.5585944652557373\n",
            "Epoch 4: Train error: 0.921875, Train loss: 3.5585947036743164, Val error: 0.921875, Val loss: 3.467223644256592\n",
            "Epoch 5: Train error: 0.875, Train loss: 3.46722412109375, Val error: 0.875, Val loss: 3.4252514839172363\n",
            "Epoch 6: Train error: 0.875, Train loss: 3.4252512454986572, Val error: 0.875, Val loss: 3.3151462078094482\n",
            "Epoch 7: Train error: 0.875, Train loss: 3.3151464462280273, Val error: 0.875, Val loss: 3.2621352672576904\n",
            "Epoch 8: Train error: 0.890625, Train loss: 3.2621352672576904, Val error: 0.890625, Val loss: 3.190049886703491\n",
            "Epoch 9: Train error: 0.859375, Train loss: 3.190049886703491, Val error: 0.859375, Val loss: 3.093668222427368\n",
            "Epoch 10: Train error: 0.828125, Train loss: 3.093667984008789, Val error: 0.828125, Val loss: 2.9858438968658447\n",
            "Epoch 11: Train error: 0.765625, Train loss: 2.9858438968658447, Val error: 0.765625, Val loss: 2.86824369430542\n",
            "Epoch 12: Train error: 0.625, Train loss: 2.868243932723999, Val error: 0.625, Val loss: 2.71877384185791\n",
            "Epoch 13: Train error: 0.640625, Train loss: 2.71877384185791, Val error: 0.640625, Val loss: 2.574019432067871\n",
            "Epoch 14: Train error: 0.734375, Train loss: 2.57401967048645, Val error: 0.734375, Val loss: 2.7090466022491455\n",
            "Epoch 15: Train error: 0.734375, Train loss: 2.7090468406677246, Val error: 0.734375, Val loss: 2.462920904159546\n",
            "Epoch 16: Train error: 0.671875, Train loss: 2.462920904159546, Val error: 0.671875, Val loss: 2.406367540359497\n",
            "Epoch 17: Train error: 0.640625, Train loss: 2.4063680171966553, Val error: 0.640625, Val loss: 2.2567150592803955\n",
            "Epoch 18: Train error: 0.640625, Train loss: 2.2567150592803955, Val error: 0.640625, Val loss: 2.1925387382507324\n",
            "Epoch 19: Train error: 0.5625, Train loss: 2.1925384998321533, Val error: 0.5625, Val loss: 2.0130598545074463\n",
            "Epoch 20: Train error: 0.578125, Train loss: 2.0130600929260254, Val error: 0.578125, Val loss: 1.8514938354492188\n",
            "Epoch 21: Train error: 0.578125, Train loss: 1.8514938354492188, Val error: 0.578125, Val loss: 1.7927765846252441\n",
            "Epoch 22: Train error: 0.515625, Train loss: 1.7927765846252441, Val error: 0.515625, Val loss: 1.6359928846359253\n",
            "Epoch 23: Train error: 0.515625, Train loss: 1.6359926462173462, Val error: 0.515625, Val loss: 1.5230318307876587\n",
            "Epoch 24: Train error: 0.453125, Train loss: 1.5230317115783691, Val error: 0.453125, Val loss: 1.3908309936523438\n",
            "Epoch 25: Train error: 0.390625, Train loss: 1.3908309936523438, Val error: 0.390625, Val loss: 1.2257989645004272\n",
            "Epoch 26: Train error: 0.359375, Train loss: 1.2257990837097168, Val error: 0.359375, Val loss: 1.1670172214508057\n",
            "Epoch 27: Train error: 0.28125, Train loss: 1.1670171022415161, Val error: 0.28125, Val loss: 1.076809287071228\n",
            "Epoch 28: Train error: 0.28125, Train loss: 1.076809287071228, Val error: 0.28125, Val loss: 0.9674506187438965\n",
            "Epoch 29: Train error: 0.3125, Train loss: 0.9674506783485413, Val error: 0.3125, Val loss: 0.9141589403152466\n",
            "Epoch 30: Train error: 0.28125, Train loss: 0.9141588807106018, Val error: 0.28125, Val loss: 0.828635573387146\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = TrafficSignModel()\n",
        "train_net(model, train_loader, train_loader, batch_size=64, learning_rate=0.01, num_epochs=30)"
      ],
      "metadata": {
        "id": "lXivTMF7Ig6A",
        "outputId": "91f1ddf0-512c-433b-ac5f-485cac525300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train error: 0.9436936936936937, Train loss: 3.515002762956871, Val error: 0.9436936936936937, Val loss: 3.5121813878166876\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-087f3e0572e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrafficSignModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-d7ef62f10d55>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(net, train_loader, val_loader, batch_size, learning_rate, num_epochs)\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtrain_err\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_train_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mval_err\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-4ee893fe03b2>\u001b[0m in \u001b[0;36mget_error\u001b[0;34m(net, data_loader)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mevaluate_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/gtsrb.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jordan just playing around to try to get a dataloader object\n",
        "I'm using Lab 2 as a guide"
      ],
      "metadata": {
        "id": "RglKHhQ0EC1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figuring out the structure of the dataset"
      ],
      "metadata": {
        "id": "0gTPskEHI89Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(gtsrb_data))\n",
        "print(gtsrb_data)\n",
        "print(len(gtsrb_data))\n",
        "print(gtsrb_data[10000][1])"
      ],
      "metadata": {
        "id": "_8iq5EPABv2J",
        "outputId": "6cdf0d84-e7ac-47e6-8a41-62fed429fd90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torchvision.datasets.gtsrb.GTSRB'>\n",
            "Dataset GTSRB\n",
            "    Number of datapoints: 26640\n",
            "    Root location: data\n",
            "26640\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using some helper functions that I've slightly modified from Lab 2"
      ],
      "metadata": {
        "id": "MM_1SnduI_lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relevant_indices(dataset, classes, target_classes):\n",
        "    \"\"\" Return the indices for datapoints in the dataset that belongs to the\n",
        "    desired target classes, a subset of all possible classes.\n",
        "\n",
        "    Args:\n",
        "        dataset: Dataset object\n",
        "        classes: A list of strings denoting the name of each class\n",
        "        target_classes: A list of strings denoting the name of desired classes\n",
        "                        Should be a subset of the 'classes'\n",
        "    Returns:\n",
        "        indices: list of indices that have labels corresponding to one of the\n",
        "                 target classes\n",
        "    \"\"\"\n",
        "    indices = []\n",
        "    for i in range(len(dataset)):\n",
        "        # Check if the label is in the target classes\n",
        "        label_index = dataset[i][1] # ex: 3\n",
        "        # label_class = classes[label_index] # ex: 'cat'\n",
        "        if label_index in target_classes:\n",
        "            indices.append(i)\n",
        "    return indices\n",
        "\n",
        "def get_data_loader(target_classes, batch_size):\n",
        "    \"\"\" Loads images of signs, splits the data into training, validation\n",
        "    and testing datasets. Returns data loaders for the three preprocessed datasets.\n",
        "\n",
        "    Args:\n",
        "        target_classes: A list of ints denoting the index of the desired\n",
        "                        classes. Should be a subset of the argument 'classes'\n",
        "        batch_size: A int representing the number of samples per batch\n",
        "    \n",
        "    Returns:\n",
        "        train_loader: iterable training dataset organized according to batch size\n",
        "        val_loader: iterable validation dataset organized according to batch size\n",
        "        test_loader: iterable testing dataset organized according to batch size\n",
        "        classes: A list of ints denoting the index of each class\n",
        "    \"\"\"\n",
        "\n",
        "    classes = tuple(range(0,43))\n",
        "    ########################################################################\n",
        "    # The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "    # We transform them to Tensors of normalized range [-1, 1].\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    # Load GTSRB training data\n",
        "    trainset = torchvision.datasets.GTSRB(root='./data', split='train', transform=transform, download=True)\n",
        "    # Get the list of indices to sample from\n",
        "    relevant_indices = get_relevant_indices(trainset, classes, target_classes)\n",
        "    \n",
        "    # Split into train and validation\n",
        "    np.random.seed(1000) # Fixed numpy random seed for reproducible shuffling\n",
        "    np.random.shuffle(relevant_indices)\n",
        "    split = int(len(relevant_indices) * 0.8) #split at 80%\n",
        "    \n",
        "    # split into training and validation indices\n",
        "    relevant_train_indices, relevant_val_indices = relevant_indices[:split], relevant_indices[split:]  \n",
        "    train_sampler = SubsetRandomSampler(relevant_train_indices)\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                               num_workers=1, sampler=train_sampler)\n",
        "    val_sampler = SubsetRandomSampler(relevant_val_indices)\n",
        "    val_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                              num_workers=1, sampler=val_sampler)\n",
        "    # Load GTSRB testing data\n",
        "    testset = torchvision.datasets.GTSRB(root='./data', split='test', transform=transform, download=True)\n",
        "    # Get the list of indices to sample from\n",
        "    relevant_test_indices = get_relevant_indices(testset, classes, target_classes)\n",
        "    test_sampler = SubsetRandomSampler(relevant_test_indices)\n",
        "    test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                             num_workers=1, sampler=test_sampler)\n",
        "    return train_loader, val_loader, test_loader, classes"
      ],
      "metadata": {
        "id": "PMcCU1TfEJ_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = tuple(range(0,43))\n",
        "target_classes = (0,)\n",
        "print(type(classes[0]))\n",
        "print(classes)\n",
        "indices_class_0 = get_relevant_indices(gtsrb_data, classes, target_classes)\n",
        "print(indices_class_0) # Now I have the indices in gtsrb_data of ClassId=0\n",
        "\n",
        "# Get data loaders for training, validation, and test sets (images are only of ClassId=0)\n",
        "train_loader, val_loader, test_loader, classes = get_data_loader(target_classes, batch_size=5)"
      ],
      "metadata": {
        "id": "6fhhJ_GRFEQI",
        "outputId": "a693a657-8cd0-4f3d-f37c-8bcdf74c6cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "18f68af9e91a49acaa541f0463cfb36a",
            "b02e126338c94e878d321e40b1ab59f2",
            "cdf41bca3ff240d38877b2cb9565d83e",
            "602e33f8c1974c14a991bcae0820f714",
            "8f91ea6e3e5b41bc85c6674d55184940",
            "d0b82a851a2649db891e5bd1484d9036",
            "7dd0618027874d5f8ed7d0eed465ea25",
            "1ad2cc7cebaa4a2a85b89bd27849a7cb",
            "3c634bdc5c5f496f89d6b609768f5018",
            "0d9f8f8c83f74fba85d4ee0987a7d82b",
            "e346e1c00a0a4710a10ed08c4881597b",
            "445ebcf804a74521a6f0a5283e7d9620",
            "c901038e6ac841008ba3797790fc70d1",
            "788fa265440e4209b8b934fa8fe3004c",
            "63519c35742a4300afbf88ad43b15d58",
            "594f7b85bd614bdb93fecc85bbf03b8f",
            "c21754109c55485ab7fd0b2d434ec80a",
            "c6e3531f4bde41bda2b4fbe9fb40c4d9",
            "c2b06654ce814555815815f53eb3d8b9",
            "155f231b8c7c4e138a7ae722acd465a7",
            "57a0150aa803494e895688a88b448327",
            "c97c1afc49724b1a9f0efc18c49d8069"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'int'>\n",
            "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42)\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
            "Downloading https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_Images.zip to data/gtsrb/GTSRB_Final_Test_Images.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/88978620 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18f68af9e91a49acaa541f0463cfb36a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/gtsrb/GTSRB_Final_Test_Images.zip to data/gtsrb\n",
            "Downloading https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_GT.zip to data/gtsrb/GTSRB_Final_Test_GT.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/99620 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "445ebcf804a74521a6f0a5283e7d9620"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/gtsrb/GTSRB_Final_Test_GT.zip to data/gtsrb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Playing around with data loaders I created above\n",
        "print(len(train_loader)) # There are 24 batches (5 images/batch) in the train loader -> This is 120 images which is 80% of 150!\n",
        "print(len(val_loader)) # There are 6 batches (5 images/batch) in the val loader -> This is 30 images which is 20% of 150\n",
        "print(len(test_loader)) # There are 12 batches (5 images/batch) in the test loader -> This is 60 images"
      ],
      "metadata": {
        "id": "SIr_MqG5P1Wi",
        "outputId": "b6c7ba54-99d5-4c87-b5ce-96050440e0d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n",
            "6\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next I'll try to plot some of the images, just to see what we're working with\n",
        "\n",
        "I don't think this is working because the images are of different sizes, we'll have to figure out what we're doing about this."
      ],
      "metadata": {
        "id": "wyiDh_OrQg1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 0\n",
        "for images, labels in enumerate(train_loader):\n",
        "    # since batch_size = 5, there are 5 images in 'images'\n",
        "    for i in range(0,5):\n",
        "      image = images[i]\n",
        "      # place the colour channel at the end, instead of at the beginning\n",
        "      img = np.transpose(image, [1,2,0])\n",
        "      # normalize pixel intensity values to [0, 1]\n",
        "      img = img / 2 + 0.5\n",
        "      plt.subplot(3, 5, k+1)\n",
        "      plt.axis('off')\n",
        "      plt.imshow(img)\n",
        "\n",
        "    k += 1\n",
        "    if k > 14:\n",
        "        break"
      ],
      "metadata": {
        "id": "TbPtVo8hRhrR",
        "outputId": "e18f3a9a-945f-48cc-da38-d581d199ce3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-2848bf2cd795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# since batch_size = 5, there are 5 images in 'images'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 175, in default_collate\n    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 175, in <listcomp>\n    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 141, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 31, 31] at entry 0 and [3, 36, 35] at entry 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper Functions**\n",
        "\n",
        "Will need functions to\n",
        "\n",
        "\n",
        "*   Get model name (for training)\n",
        "*   Evaluate network on validation set\n",
        "*   Plot the training curves\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "egEbz8G-zjoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Model Architecture**"
      ],
      "metadata": {
        "id": "w_KzPXjrkPwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrafficSignModel(nn.Module):\n",
        "  def __init__(self):\n",
        "     super(TrafficSignModel, self).__init__()\n",
        "     self.name = \"TrafficSignModel\"\n",
        "     self.conv1 = nn.Conv2d(3, 5, 5) # 3 input channels, 5 output channels, kernel size of 5\n",
        "     self.pool = nn.MaxPool2d(2, 2), # kernel size of 2, stride of 2\n",
        "     self.conv2 = nn.Conv2d(5, 10, 5), # 5 input channels, 10 output channels, kernel size of 5\n",
        "     self.fc1 = nn.Linear() # Will need to figure out these dimensions (based on input dimensions of image - how are we handling this?)\n",
        "     self.fc2 = nn.Linear() # Will need to figure out these dimensions (based on how many different classes we are working with - do we know?)\n",
        "         \n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, ) # Will need to figure out these dimensions - see above\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    x = x.squeeze(1) # Flatten to [batch_size]\n",
        "    return x"
      ],
      "metadata": {
        "id": "4JOOPHI2e32S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**\n",
        "\n",
        "Function to train the neural network\n",
        "Need to decide loss function and optimizer\n",
        "\n",
        "A lot of this code can be adopted from the Labs and tutorials"
      ],
      "metadata": {
        "id": "vcKCZzFM0FNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Katherine trying to augment the data"
      ],
      "metadata": {
        "id": "hAcXNqEFygYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_datasets = []\n",
        "\n",
        "my_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(25),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "for _ in range(2):\n",
        "    gtsrb_new = datasets.GTSRB('data', download=True, transform=my_transform)\n",
        "    augmented_datasets.append(gtsrb_new)\n",
        "\n",
        "concat = torch.utils.data.ConcatDataset(augmented_datasets)"
      ],
      "metadata": {
        "id": "D2mlKZzVbOdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount our Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Y_Ww0BuCsn1W",
        "outputId": "77c7e44b-c07b-42a8-8eae-48e93fc7e5ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('drive/MyDrive/APS360/Project/SyRa-Synthesized_Rain_dataset-main')"
      ],
      "metadata": {
        "id": "xaDR2GM-28cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"assets/folder_of_your_data/folder_of_your_data/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsz0Ia9VVsDp",
        "outputId": "aafea46d-dd71-4089-b26d-0e336dd7c88c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['img_2222_meditation_ashley_sharp_crop.256x256.jpg', 'outdoors.256x256.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRoYScaKZkso",
        "outputId": "23869c52-a83b-475b-bc0b-939a7d07fa85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data = get_train_data_loader(img_size=256)\n",
        "\n",
        "for i, data in enumerate(train_data):\n",
        "  img, label = data\n",
        "  for j in range(img.shape[0]):\n",
        "      torchvision.utils.save_image(img[j,:,:,:], 'assets/folder_of_your_data/folder_of_your_data/{}{}.png'.format(i,j))\n",
        "  if i>=0:\n",
        "    break"
      ],
      "metadata": {
        "id": "frhsUX1aPbwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install munch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpR5VVyBsmZF",
        "outputId": "d95f8887-f576-47d4-d148-0c8edad1ec92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch) (1.15.0)\n",
            "Installing collected packages: munch\n",
            "Successfully installed munch-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XOInrzftQD_",
        "outputId": "f848e77e-a429-4567-bcb3-0b398085d197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6084 sha256=344a5e2ab1a0b6c3a1c4521d57723b585f4f054938f3190d25b69ee2816b5ae0\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/80/6e/caa3e16deb0267c3cbfd36862058a724144e19fdb9eb03af0f\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import munch\n",
        "import ffmpeg\n",
        "import os"
      ],
      "metadata": {
        "id": "r33Bjf_DstXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('drive/MyDrive/APS360/Project/SyRa-Synthesized_Rain_dataset-main')"
      ],
      "metadata": {
        "id": "-X-yAwXgs4fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "python main.py --img_size 256 --mode syn --checkpoint_dir expr/checkpoint/SyRa --out_dir expr/result --data folder_of_your_data --resume_iter 100000"
      ],
      "metadata": {
        "id": "cyGDEPOkz2lh",
        "outputId": "285b019a-b805-43aa-b656-6d581799a483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA_number : 0\n",
            "Namespace(batch_size=8, beta1=0.01, beta2=0.99, checkpoint_dir='expr/checkpoint/SyRa', data='folder_of_your_data', ds_iter=150000, eval_dir='expr/eval/SyRa', f_lr=1e-06, gpu=0, gt=1, hidden_dim=512, img_size=256, lambda_NPMI=0.1, lambda_SGD=0.1, lambda_cyc=1, lambda_ds=1, lambda_reg=1, lambda_sty=1, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='syn', num_domains=2, num_outs_per_domain=5, num_workers=4, out_dir='expr/result', print_every=10, rain_dir='assets', randcrop_prob=0.5, ref_dir='assets/representative/yose/ref', result_dir='expr/results', resume_iter=100000, sample_dir='expr/samples/SyRa', sample_every=10000, save_every=10000, seed=777, src_dir='assets/representative/yose/src', style_dim=64, total_iters=100000, train_img_dir='data/rains/train', val_batch_size=10, val_img_dir='data/rains/val', w_hpf=0, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n",
            "Number of parameters of generator: 33991564\n",
            "Number of parameters of mapping_network: 2438272\n",
            "Number of parameters of style_encoder: 20916928\n",
            "Number of parameters of discriminator: 20852290\n",
            "Initializing generator...\n",
            "Initializing mapping_network...\n",
            "Initializing style_encoder...\n",
            "Initializing discriminator...\n",
            "Preparing DataLoader for the generation phase...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Loading checkpoint from expr/checkpoint/SyRa/100000_nets_ema.ckpt...\n",
            " 50% 3/6 [00:10<00:10,  3.57s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 189, in <module>\n",
            "    main(args)\n",
            "  File \"main.py\", line 68, in main\n",
            "    solver.synthesis(loaders)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/APS360/Project/SyRa-Synthesized_Rain_dataset-main/core/solver.py\", line 175, in synthesis\n",
            "    utils.synthesis_image(nets_ema, args, inputs=inputs_val, step=i)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/APS360/Project/SyRa-Synthesized_Rain_dataset-main/core/utils.py\", line 121, in synthesis_image\n",
            "    [save_image(x_src[y], 1, ospj(args.out_dir+'/%04d' % (args.val_batch_size*step+y), 'Clear.jpg')) for y in range(args.val_batch_size)]\n",
            "  File \"/content/drive/MyDrive/APS360/Project/SyRa-Synthesized_Rain_dataset-main/core/utils.py\", line 121, in <listcomp>\n",
            "    [save_image(x_src[y], 1, ospj(args.out_dir+'/%04d' % (args.val_batch_size*step+y), 'Clear.jpg')) for y in range(args.val_batch_size)]\n",
            "IndexError: index 3 is out of bounds for dimension 0 with size 3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c1cbdda43b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'python main.py --img_size 256 --mode syn --checkpoint_dir expr/checkpoint/SyRa --out_dir expr/result --data folder_of_your_data --resume_iter 100000\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m       raise subprocess.CalledProcessError(\n\u001b[0;32m--> 135\u001b[0;31m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'python main.py --img_size 256 --mode syn --checkpoint_dir expr/checkpoint/SyRa --out_dir expr/result --data folder_of_your_data --resume_iter 100000\n' returned non-zero exit status 1."
          ]
        }
      ]
    }
  ]
}