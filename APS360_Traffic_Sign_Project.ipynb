{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katL7/GTSRB-APS360/blob/Fixed_tran_val_loader/APS360_Traffic_Sign_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "FwK5G34Jx_Ez"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KcORCBgQ_2zK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from google.colab import drive\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = True"
      ],
      "metadata": {
        "id": "JemGhh_1Kh3m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test Change"
      ],
      "metadata": {
        "id": "u4-ZnaW8-d2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "Bamt_XDHyJyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split into training, validation and test - stratify each\n",
        "def get_val_test_loader(batch_size=64, img_size=50):\n",
        "    # Rescale images to all be the same size\n",
        "    data_transform = transforms.Compose([transforms.Resize((img_size,img_size)), \n",
        "                                         transforms.ToTensor()])\n",
        "\n",
        "    # Get paths to data in folder\n",
        "    gtsrb_data = datasets.GTSRB('data', download=True, split='test',\n",
        "                           transform=data_transform)\n",
        "\n",
        "    class_idxs = {}\n",
        "    #Loop through filenames and sort into classes\n",
        "    for i, data in enumerate(gtsrb_data):\n",
        "        img, label = data\n",
        "        if label in class_idxs:\n",
        "          class_idxs[label].append(i)\n",
        "        else:\n",
        "          class_idxs[label] = [i]\n",
        "\n",
        "    np.random.seed(1000)\n",
        "    test_indices = []\n",
        "    val_indices = []\n",
        "\n",
        "    for class_key in class_idxs:\n",
        "      #Split validation/testing indices as 0.7/0.3 split by class\n",
        "      np.random.shuffle(class_idxs[class_key])\n",
        "      split = int(len(class_idxs[class_key]) * 0.7)\n",
        "      val_indices += class_idxs[class_key][:split]\n",
        "      test_indices += class_idxs[class_key][split:]\n",
        "\n",
        "    #Shuffle the testing/validation indices\n",
        "    np.random.shuffle(test_indices)\n",
        "    np.random.shuffle(val_indices)\n",
        "\n",
        "    #testing data loader\n",
        "    test_sampler = SubsetRandomSampler(test_indices)\n",
        "    test_loader = torch.utils.data.DataLoader(gtsrb_data, batch_size=batch_size,\n",
        "          num_workers=0, sampler=test_sampler)\n",
        "\n",
        "    #Validation data loader\n",
        "    val_sampler = SubsetRandomSampler(val_indices)\n",
        "    val_loader = torch.utils.data.DataLoader(gtsrb_data, batch_size=batch_size,\n",
        "          num_workers=0, sampler=val_sampler)\n",
        "    \n",
        "    return val_loader, test_loader"
      ],
      "metadata": {
        "id": "8e1zsJIX1uKP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_data_loader(batch_size=64, img_size=50):\n",
        "    # Rescale images to all be the same size\n",
        "    data_transform = transforms.Compose([transforms.Resize((img_size,img_size)), \n",
        "                                         transforms.ToTensor()])\n",
        "\n",
        "    # Get paths to data in folder\n",
        "    data = datasets.GTSRB('data', download=True, split=\"train\",\n",
        "                          transform=data_transform)\n",
        "  \n",
        "    np.random.seed(1000)\n",
        "    #train data loader\n",
        "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size,\n",
        "          num_workers=0, shuffle=True)\n",
        "    \n",
        "    return train_loader\n",
        "\n"
      ],
      "metadata": {
        "id": "cJ4zLm18CYVS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader, test_loader = get_val_test_loader(64)"
      ],
      "metadata": {
        "id": "_u0ZknId8qib",
        "outputId": "ce95e5b8-3081-4338-efbb-0621b3a35f96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5806, 557, 11070, 1547, 8577, 501, 1688, 2955, 4054, 10100, 5121, 9581, 11459, 6534, 5480, 10975, 12407, 12534, 10311, 12266, 5909, 2256, 3693, 3809, 2382, 10042, 11241, 10929, 740, 6525, 6755, 10437, 12155, 985, 5975, 10681, 5456, 1999, 147, 5004, 3474, 2459, 11486, 4087, 497, 11978, 9532, 8427, 6703, 12520, 10642, 7289, 4440, 4012, 9190, 11183, 12364, 8653, 310, 8724, 4715, 2473, 1722, 5206, 10776, 2967, 12455, 3520, 9938, 3242, 3527, 8042, 12, 893, 4240, 7133, 9771, 3320, 6190, 11642, 3613, 10690, 10173, 3637, 384, 9396, 9629, 11928, 6057, 3299, 10602, 8791, 6863, 9833, 8769, 137, 4854, 5458, 1112, 9047, 1532, 12552, 5037, 8258, 8840, 1150, 736, 7620, 10668, 4933, 7835, 7605, 4387, 1741, 1668, 7920, 2025, 9829, 7772, 8541, 3824, 3249, 2851, 4358, 8287, 1363, 12276, 4114, 4531, 9554, 2122, 12003, 8742, 5848, 10722, 12283, 8397, 8700, 7275, 11838, 12303, 9477, 7420, 7050, 1403, 2087, 3813, 6501, 2441, 2592, 5401, 1602, 3670, 5850, 5198, 9159, 1201, 3980, 1279, 4386, 4451, 1790, 6437, 1752, 7755, 956, 2754, 2271, 1346, 1063, 11483, 194, 6424, 2396, 3769, 6467, 8202, 1982, 9440, 16, 9566, 2313, 5917, 9831, 6803, 2204, 5441, 11534, 11644, 9145, 5127, 2992, 423, 1304, 9996, 9615, 10195, 1618, 3086, 10570, 7847, 6622, 7257, 7197, 1071, 10730, 8270, 523, 11895, 6336, 2013, 8827, 3486, 6286, 2740, 11518, 5126, 8951, 11301, 8072, 10503, 4635, 5947, 3841, 1035, 3127, 115, 7426, 1397, 3264, 6585, 11382, 11830, 12473, 8839, 10037, 5465, 8731, 7508, 3147, 4941, 9033, 5556, 10406, 2284, 9953, 7235, 1172, 6309, 6977, 11092, 5354, 12459, 10727, 7913, 3032, 6600, 11896, 2187, 385, 5570, 4822, 6613, 8495, 3377, 5132, 6514, 6631, 7774, 790, 2559, 7097, 7063, 974, 815, 11431, 118, 12315, 11238, 11774, 5705, 6776, 7322, 11467, 8610, 9357, 970, 3133, 10723, 12369, 1784, 152, 828, 3446, 5540, 4807, 7390, 12089, 5712, 1503, 4492, 7053, 2448, 8804, 8581, 2985, 12462, 10109, 12544, 4278, 5982, 7621, 7170, 6881, 2008, 8905, 5010, 11810, 7628, 2685, 6218, 11192, 43, 6756, 9811, 7670, 1928, 7010, 11883, 1147, 8838, 2591, 1644, 6297, 6858, 11476, 7313, 11186, 7150, 8439, 8712, 5544, 6993, 8686, 10731, 12083, 4980, 7659, 6850, 1043, 10484, 9438, 9259, 375, 9564, 1639, 7927, 2316, 8551, 9128, 7733, 11402, 8347, 1198, 1727, 3083, 9569, 12180, 6256, 2167, 275, 944, 6486, 717, 4594, 1998, 10593, 7311, 12149, 5647, 8228, 11690, 2611, 5491, 2674, 11993, 4652, 11308, 5488, 8383, 6113, 10497, 2359, 2381, 4988, 5081, 4658, 7504, 11343, 8871, 2129, 1819, 2668, 1663, 10276, 8067, 1809, 11474, 7205, 7503, 1943, 3482, 8958, 6887, 5389, 306, 10836, 10068, 3026, 4027, 308, 7414, 5381, 1315, 11229, 3638, 6924, 6104, 6321, 11048, 6171, 5845, 1251, 3984, 8779, 11628, 2376, 7293, 9898, 1496, 659, 7362, 5507, 7837, 649, 8669, 3332, 9184, 5180, 8943, 6126, 12108, 10185, 5822, 9596, 5322, 11257, 6540, 6804, 4026, 5128, 5993, 7114, 11977, 3288, 4144, 10375, 10207, 8480, 3362, 8049, 8401, 3072, 2233, 106, 1687, 10528, 5276, 8193, 10586, 10918, 6982, 10666, 1505, 6735, 5938, 3749, 11209, 7393, 10810, 2823, 2528, 6959, 1324, 9325, 9171, 10575, 508, 7221, 8144, 1679, 904, 4363, 1049, 8973, 10767, 11613, 1569, 5825, 4763, 2731, 9711, 7834, 2255, 4063, 10891, 4514, 9439, 352, 5678, 186, 12408, 4694, 4557, 58, 9332, 5028, 285, 4115, 7604, 4861, 3087, 6314, 3353, 2154, 8187, 10870, 7421, 11242, 1210, 136, 5093, 6278, 83, 490, 9007, 3071, 7251, 10864, 7520, 3739, 506, 2642, 6752, 5047, 7074, 2519, 4552, 12115, 7406, 2548, 11044, 5734, 8857, 686, 3107, 3802, 7911, 8533, 11120, 2352, 9756, 12395, 922, 8355, 10415, 6120, 2762, 1869, 9344, 958, 5839, 11948, 279, 9483, 10487, 7677, 880, 11783, 9862, 825, 9507, 8606, 3815, 12346, 6346, 5420, 11294, 8233, 12451, 10501, 6242, 9215, 9789, 2126, 12423, 4155, 10349, 3368, 2198, 1237, 5824, 12362, 766, 3139, 805, 8192, 4428, 11464, 834, 12045, 5623, 10535, 8982, 11712, 10841, 12047, 9919, 5059, 2839, 919, 10242, 9433, 5350, 313, 5609, 10671, 9426, 3592, 8602, 1124, 2053, 5419, 8381, 11357, 7129, 761, 1577, 3731, 4978, 2127, 9189, 1183, 4355, 2826, 3615, 11580, 11167, 10738, 11306, 9654, 9186, 468, 11094, 7651, 1901, 193, 2323, 5374, 1854, 9520, 4461, 10951, 12090, 7869, 10177, 11809, 2732, 3774, 3578, 9188, 11803, 7450, 7907, 6813, 4841, 4281, 9484, 11075, 1460, 6702, 2294, 7527, 3357, 6604, 11182, 5285, 8189, 12604, 4644, 12326, 2170, 2149, 9742, 3735, 7163, 7277, 1988, 12030, 608, 8300, 12560, 8273, 7350, 8152, 422, 11332, 341, 3091, 3171, 3811, 8771, 7686, 11687, 5176, 4950, 1515, 4503, 1599, 1024, 4326, 6356, 11723, 9213, 4749, 7951, 9154, 8666, 2812, 10354, 1297, 11939, 9172, 6589, 11976, 8303, 11550, 8337, 5413, 6468, 7852, 11593, 9885, 5342, 6906, 5447, 4871, 9575, 594, 5111, 3106, 862, 11421, 7803, 10800, 3830, 353, 3758, 8557, 1793, 12079, 9333, 5599, 5046, 10167, 7883, 3185, 11936, 444, 474, 6640, 1464, 3233, 4526, 2369, 6576, 10608, 2986, 11507, 5107, 8758, 2952, 7777, 7110, 8338, 8105, 8043, 3066, 10907, 9144, 9369, 9966, 5833, 4327, 54, 4255, 12059, 9962, 11159, 9823, 6599, 4383, 1948, 2761, 8535, 961, 1485, 415, 5159, 6320, 10622, 5787, 6152, 23, 4698, 4271, 3208, 3196, 759, 2867, 2852, 2600, 8249, 8812, 744, 9636, 5732, 5922, 9968, 1634, 5900, 11756, 6720, 3640, 2480, 3976, 11852, 1633, 5024, 7304, 4907, 6197, 9109, 10507, 3546, 850, 2728, 2902, 8266, 4032, 3473, 2873, 1764, 10356, 4689, 2245, 1870, 1563, 6570, 6080, 325, 6252, 12035, 9755, 8992, 8438, 12330, 8082, 10571, 9228, 4470, 2926, 9671, 11819, 10513, 1786, 1751, 1734, 3529, 5754, 3843, 9589, 2481, 6072, 10240, 2311, 11499, 8243, 6154, 2022, 6769, 307, 8927, 11374, 3689, 60, 4014, 3791, 3027, 9271, 10533, 1882, 4160, 5304, 12609, 4485, 526, 1028, 1065, 739, 4474, 6004, 10658, 10692, 404, 3889, 4768, 4553, 10965, 8466, 3105, 5434, 6512, 8693, 9893, 976, 6533, 480, 11609, 8748, 1322, 7534, 9353, 72, 6980, 11570, 9599, 7237, 3063, 12106, 1682, 2354, 7164, 11414, 714, 5602, 1522, 6049, 105, 1808, 9679, 9290, 8621, 8622, 4714, 8947, 7162, 8831, 3588, 10046, 8968, 5372, 3954, 12302, 9909, 10911, 10511, 4832, 9846, 11087, 1519, 1380, 8034, 7582, 4308, 7418, 7819, 1524, 224, 11223, 9013, 2033, 8768, 3160, 2653, 11711, 9112, 9881, 4441, 362, 5179, 9071, 4986, 8891, 760, 8569, 8829, 392, 12352, 1158, 6663, 10843, 3366, 5717, 3837, 1492, 4875, 8572, 8894, 823, 2403, 2180, 4982, 10689, 10616, 5971, 11622, 5122, 12602, 10482, 12166, 9130, 12147, 7988, 8628, 7047, 6461, 9253, 3407, 4972, 4379, 1163, 10894, 1481, 1525, 7899, 12569, 6038, 7952, 12444, 9422, 10828, 7728, 808, 7502, 11281, 8625, 11623, 2042, 5869, 2877, 3003, 3370, 7357, 2491, 428, 10736, 1881, 9905, 4291, 1136, 8859, 4985, 9766, 6710, 3399, 4344, 3467, 763, 4275, 2983, 7830, 6198, 10772, 1597, 5452, 6860, 5062, 5015, 5357, 11344, 9085, 6565, 12627, 5696, 258, 2727, 12188, 5051, 10909, 11214, 73, 2500, 1325, 2845, 5749, 2018, 4680, 9460, 2964, 4217, 6936, 3948, 6844, 5758, 1233, 5851, 1714, 998, 3659, 10578, 2392, 1411, 5781, 11248, 1520, 6829, 8027, 2372, 1323, 2039, 4073, 9552, 130, 4709, 3259, 3609, 9330, 707, 8354, 9825, 6240, 735, 7704, 5974, 10044, 9317, 3414, 8540, 5369, 728, 8176, 12206, 6783, 1845, 3856, 11473, 11328, 10476, 11270, 6371, 690, 11779, 5269, 1268, 11049, 8344, 11166, 2897, 5627, 4481, 10208, 5333, 8739, 7846, 3879, 11033, 2325, 3489, 11052, 3354, 4290, 3796, 8231, 11225, 1857, 9266, 2437, 1670, 11571, 7809, 4962, 10452, 5944, 1978, 3674, 8086, 4086, 9841, 8296, 3153, 6971, 9226, 5548, 10491, 6686, 10584, 10924, 28, 2215, 3219, 345, 7969, 11100, 8340, 10304, 6067, 9929, 6086, 10761, 2755, 9722, 9607, 11296, 10264, 592, 3444, 6952, 4018, 6277, 6549, 11832, 3550, 9883, 7320, 5104, 11569, 1055, 8267, 6484, 6730, 3508, 10594, 6047, 2718, 7344, 2529, 1213, 7792, 5139, 9233, 11746, 4306, 11772, 8485, 5610, 3868, 8817, 2280, 12522, 5883, 1671, 9768, 8607, 280, 9978, 10647, 10892, 231, 3754, 8532, 8584, 10028, 5814, 7876, 317, 12144, 1009, 6917, 2684, 894, 3823, 8063, 3853, 1721, 6243, 5390, 8626, 4193, 3108, 9830, 3941, 9469, 11124, 1806, 135, 12422, 8286, 86, 2488, 10651, 938, 5929, 8325, 5454, 3372, 5746, 7747, 10974, 4964, 9027, 2626, 78, 1831, 11489, 8503, 7862, 4675, 11286, 681, 9291, 7202, 1625, 6195, 8217, 8277, 10248, 7223, 2179, 9772, 1379, 1876, 5074, 8290, 1119, 6485, 4133, 10394, 154, 2703, 1284, 3129, 9143, 11528, 5662, 3237, 1413, 10988, 7091, 6700, 7059, 4056, 4208, 581, 11631, 9268, 1558, 10228, 9651, 11142, 5811, 6176, 1111, 957, 4301, 421, 12046, 1388, 295, 10765, 3647, 10792, 5450, 12577, 11727, 2917, 1586, 10151, 8967, 8972, 7606, 11346, 4213, 11843, 9083, 8919, 10876, 8400, 10534, 10917, 11180, 9237, 9555, 3431, 9004, 2439, 10819, 4377, 10862, 3528, 188, 10263, 12628, 9176, 1052, 9434, 11689, 201, 8525, 10059, 318, 11553, 7495, 4631, 19, 9797, 9169, 4897, 8362, 949, 6024, 10669, 6207, 8658, 2977, 9063, 10256, 10308, 668, 4774, 11158, 1160, 9150, 9135, 286, 570, 6550, 5522, 4563, 3599, 6797, 10289, 3846, 10702, 3789, 3863, 3406, 11045, 7681, 4452, 433, 11943, 12195, 5963, 10031, 588, 2542, 463, 3338, 9547, 1048, 9925, 10283, 7699, 437, 7042, 429, 3001, 705, 10667, 2069, 11915, 1428, 7971, 8655, 1378, 10540, 6948, 5798, 2329, 7457, 9539, 11991, 12450, 7929, 5985, 6957, 4112, 11547, 9677, 9942, 10903, 10641, 2884, 467, 2802, 10282, 11639, 6385, 11444, 1133, 3384, 8165, 2213, 8414, 2145, 2419, 7748, 3305, 1226, 3885, 3575, 7526, 1938, 5199, 7685, 10999, 9837, 7524, 5392, 3289, 1415, 7033, 7321, 6577, 405, 163, 4860, 7652, 2218, 8181, 3126, 8154, 10418, 7043, 3314, 923, 11963, 8600, 329, 5795, 1041, 8660, 11076, 5639, 9061, 1192, 4842, 8615, 2587, 12512, 7848, 5823, 6590, 1382, 7200, 768, 6464, 11857, 12559, 8455, 6221, 4009, 9816, 2257, 3612, 926, 599, 2358, 1842, 543, 11305, 1372, 9839, 12354, 458, 10532, 7531, 4319, 8516, 1239, 3506, 3277, 11290, 3497, 8729, 5821, 3140, 1573, 8, 9388, 2829, 8855, 1457, 1672, 9986, 10720, 12010, 6757, 571, 5250, 2820, 7166, 5049, 11012, 3464, 8991, 12337, 12187, 3123, 8179, 470, 3942, 32, 6292, 9039, 10837, 195, 969, 6477, 12470, 1872, 5953, 1399, 3046, 3339, 8005, 8596, 2930, 7232, 3096, 5566, 10400, 727, 9750, 4105, 430, 2036, 1036, 6412, 1536, 8369, 9152, 1775, 3971, 7307, 11379, 12507, 12601, 7246, 39, 616, 9542, 3937, 2994, 7798, 11202, 7766, 4845, 547, 11068, 7779, 5799, 3511, 4390, 7014, 4625, 12050, 2383, 7085, 1238, 10826, 9514, 10786, 4020, 3007, 6761, 2333, 8402, 6164, 9822, 10290, 12114, 1171, 1105, 8264, 2023, 10325, 420, 9115, 8408, 2450, 2200, 4776, 8151, 10317, 8321, 2623, 10074, 4571, 5654, 8969, 5255, 4622, 2211, 3510, 5485, 8453, 11024, 7130, 697, 7960, 5393, 10161, 849, 11654, 6078, 1979, 10640, 12238, 6899, 5321, 8566, 11416, 4331, 1572, 1358, 11595, 711, 4368, 4663, 11946, 3440, 2569, 9246, 7060, 7980, 666, 6790, 12321, 496, 7001, 7000, 2825, 11885, 10832, 9092, 6179, 6799, 6360, 7599, 243, 1818, 8471, 5753, 1140, 5248, 4765, 10279, 166, 7513, 12167, 4298, 9943, 5055, 9965, 12299, 8350, 12306, 2664, 791, 11927, 4510, 225, 4415, 3947, 11370, 10004, 324, 10544, 4620, 3905, 4702, 8002, 2927, 12134, 6251, 4239, 4031, 8730, 6802, 10297, 3531, 7142, 5497, 6288, 9731, 6560, 3364, 7231, 872, 1927, 6265, 7973, 518, 3959, 4203, 869, 6697, 2984, 6713, 11950, 6527, 6871, 11450, 6632, 207, 1835, 4990, 6574, 5409, 5597, 3904, 1689, 8209, 7671, 4199, 4672, 1539, 1676, 5265, 12553, 342, 9843, 6029, 2470, 6463, 5155, 11099, 11679, 1196, 11086, 3894, 3342, 9778, 2580, 12042, 1616, 6516, 1302, 6128, 6247, 1534, 5313, 11875, 8618, 3958, 1980, 6812, 11057, 9680, 4697, 6159, 7088, 10229, 6793, 1394, 8924, 1018, 2263, 3516, 84, 8016, 3300, 11373, 10829, 10144, 1878, 10950, 4109, 6578, 9199, 5655, 4820, 11955, 6419, 8977, 9338, 11072, 8275, 4894, 8538, 2750, 10472, 3657, 3568, 4788, 2624, 5912, 3619, 3454, 11812, 618, 9497, 3660, 10071, 9895, 11300, 12258, 10045, 9741, 6973, 3591, 9037, 2931, 6032, 7482, 8060, 9162, 4900, 1944, 12316, 1338, 5308, 8353, 389, 786, 12472, 208, 2963, 8031, 11961, 4251, 9205, 1207, 10409, 3696, 9016, 2522, 1390, 4140, 3923, 1310, 4757, 3163, 7705, 1810, 4242, 1883, 5568, 9239, 646, 4499, 334, 9791, 6466, 8227, 576, 1720, 7463, 4616, 9006, 485, 6815, 11929, 11463, 5170, 10198, 2758, 7499, 1185, 222, 4623, 9210, 1578, 665, 1257, 7072, 11906, 3559, 2438, 8069, 10005, 7724, 3392, 2451, 3177, 4496, 6093, 1263, 4837, 3058, 8668, 6121, 11458, 11303, 10156, 12410, 4469, 694, 810, 2503, 4332, 7687, 7294, 10683, 10904, 2800, 11567, 7808, 3484, 6951, 10027, 10806, 268, 9443, 10595, 6898, 240, 2544, 239, 11256, 6363, 5836, 3427, 7098, 12207, 7443, 7611, 6400, 7982, 997, 11239, 6109, 2210, 10547, 945, 483, 10627, 8781, 5918, 10101, 2925, 12142, 4471, 7045, 9040, 4502, 1638, 7121, 7976, 3784, 3726, 6422, 3564, 11921, 11958, 11425, 8360, 2020, 4342, 5921, 11761, 7930, 2708, 9580, 2807, 9757, 4341, 11047, 7500, 10825, 733, 9548, 1311, 11879, 1646, 5903, 12536, 17, 3648, 4038, 831, 2386, 12053, 4333, 5334, 159, 6270, 6848, 4131, 6913, 7537, 5774, 4905, 6975, 289, 10086, 2202, 4303, 320, 11737, 5840, 6410, 413, 9670, 8717, 3378, 1260, 10366, 5130, 11018, 8583, 10246, 12327, 4650, 11442, 4916, 3195, 6903, 710, 5726, 5897, 5637, 9331, 11258, 9906, 1889, 6556, 11178, 1404, 7963, 2370, 931, 4380, 3162, 1657, 12054, 8234, 12452, 6456, 9972, 2079, 3512, 3499, 3194, 5338, 162, 10443, 4138, 3352, 9579, 2707, 4573, 6193, 2493, 4830, 4791, 263, 1442, 8683, 11521, 6985, 5752, 12177, 8169, 12626, 5102, 7174, 10985, 7922, 8191, 8988, 1643, 10682, 2158, 5583, 12274, 8995, 5213, 1321, 12309, 10785, 350, 9, 2399, 2833, 5283, 1900, 920, 11471, 9879, 3756, 8422, 3982, 1286, 4150, 2962, 8887, 4232, 4647, 8617, 1433, 465, 9519, 9153, 6926, 5240, 12130, 12204, 10874, 3717, 2062, 7915, 7475, 9994, 7427, 7992, 4194, 4195, 9880, 215, 7327, 10372, 4296, 8511, 11653, 4367, 11355, 10070, 9979, 11085, 2726, 9699, 907, 6290, 5068, 689, 11918, 3248, 8425, 4409, 4847, 7567, 3633, 5146, 2477, 10994, 3602, 8527, 3836, 5579, 11954, 4725, 9683, 68, 3539, 5118, 5379, 3492, 11390, 3641, 5385, 10879, 9140, 9533, 4678, 6893, 10983, 6839, 2556, 5339, 8283, 7276, 1709, 7787, 12414, 8409, 3323, 2047, 7600, 7153, 7348, 11728, 8379, 864, 2015, 6614, 3180, 5101, 6928, 4082, 1556, 10500, 4125, 10615, 2511, 7807, 4151, 11122, 2798, 10365, 1406, 855, 8665, 5632, 10348, 2076, 8474, 2533, 9110, 9088, 6131, 10102, 9230, 7368, 10291, 4202, 4365, 6642, 272, 7401, 4345, 5859, 2304, 6112, 6872, 8464, 784, 6852, 8563, 3182, 2996, 10174, 10171, 5502, 5803, 8746, 6006, 10577, 11808, 248, 8946, 1962, 960, 450, 5671, 3887, 4320, 2505, 7004, 6582, 5424, 7058, 11945, 5828, 6213, 8640, 9280, 9674, 11219, 10015, 5574, 6100, 9326, 9163, 246, 3816, 5196, 1732, 3732, 3284, 9728, 8506, 11069, 1915, 3480, 3420, 9045, 5838, 1120, 10850, 10379, 182, 9481, 3079, 3298, 139, 11022, 4782, 1288, 7675, 9813, 11437, 5593, 3405, 10838, 1620, 1466, 11967, 11511, 4223, 170, 12150, 8642, 2525, 406, 10383, 4913, 11030, 12027, 8994, 3501, 6039, 8594, 8623, 4735, 9780, 11329, 2139, 9739, 713, 12603, 5163, 8819, 3573, 1031, 3710, 452, 2694, 9889, 315, 5039, 7054, 8246, 11968, 11171, 6737, 11001, 2341, 9270, 6307, 10330, 11842, 4546, 12515, 11790, 1684, 10189, 1423, 3306, 12194, 6877, 12394, 2417, 6482, 8929, 11565, 3922, 6481, 165, 3052, 10796, 9864, 435, 12490, 6478, 3122, 11020, 6705, 1458, 10019, 12246, 169, 2484, 12528, 10178, 11247, 12132, 9595, 2395, 1115, 2093, 7422, 10887, 8659, 11397, 4419, 8556, 9958, 4919, 6343, 9034, 7844, 8582, 3818, 12567, 10830, 8307, 525, 1874, 11584, 2523, 10942, 3949, 1206, 1230, 852, 10931, 8106, 6983, 8753, 6293, 8750, 11515, 4869, 4592, 11125, 9672, 4818, 2401, 12094, 8126, 3874, 6310, 11046, 5129, 530, 10680, 11056, 7451, 9289, 1977, 2275, 7081, 9415, 12157, 3294, 5251, 4924, 7751, 5711, 9256, 1800, 10488, 3855, 6017, 6521, 4545, 9775, 7936, 7398, 5989, 4551, 1636, 9686, 12033, 5757, 9200, 10057, 9704, 5365, 7559, 12541, 6332, 1582, 2034, 477, 9240, 4892, 4902, 4517, 5289, 172, 9025, 12169, 955, 6652, 8147, 2709, 8122, 9645, 12199, 7795, 5626, 8214, 131, 2676, 3541, 8727, 10880, 560, 33, 4429, 10744, 12280, 10569, 8279, 133, 204, 930, 5538, 1737, 2607, 7468, 3780, 1240, 1255, 8180, 9175, 9248, 4175, 4404, 6995, 8172, 2936, 7510, 9116, 3226, 1170, 7077, 10249, 9173, 57, 1408, 2757, 8479, 2869, 8309, 3089, 9073, 15, 2124, 6392, 10732, 9204, 11149, 11487, 1770, 1471, 1249, 2613, 6878, 3577, 1863, 4235, 9817, 70, 1953, 569, 3880, 11872, 2099, 7318, 7714, 12293, 629, 9036, 378, 4878, 7272, 11733, 4028, 5396, 2880, 3974, 1512, 7884, 2347, 7341, 7564, 6223, 319, 8849, 3118, 52, 7850, 10012, 6740, 8053, 9320, 9744, 3073, 12404, 11174, 8308, 6895, 6824, 4198, 5151, 236, 11635, 3719, 5106, 12572, 6183, 4477, 968, 11940, 3870, 4574, 11453, 3166, 7720, 8174, 5352, 799, 8138, 2978, 8092, 11287, 5879, 640, 6323, 8692, 6269, 6201, 5868, 11562, 6915, 9664, 3684, 298, 1073, 6990, 9064, 4393, 9537, 5670, 8956, 5842, 4969, 12068, 10919, 1211, 10604, 5863, 266, 2974, 1839, 354, 9053, 10359, 5680, 7271, 2, 6358, 937, 11730, 9125, 11743, 4825, 2362, 12535, 4767, 10953, 11960, 10186, 1368, 5584, 7633, 10369, 8821, 11980, 2297, 6661, 129, 3999, 7718, 7640, 12506, 4548, 4058, 10573, 7169, 6305, 146, 3639, 9526, 7826, 10621, 12011, 6347, 6947, 5692, 10148, 12269, 4353, 3557, 3080, 1474, 294, 12133, 11353, 8559, 12029, 9642, 1360, 7404, 8492, 6937, 8923, 11828, 4221, 628, 6462, 10687, 6329, 5495, 5299, 8684, 8638, 6999, 3745, 545, 2799, 12420, 12277, 10192, 683, 2631, 203, 7187, 8734, 221, 12537, 5034, 6037, 4189, 3263, 8099, 1942, 10267, 301, 11763, 1545, 3764, 3728, 10461, 211, 3724, 7217, 12075, 7343, 658, 6711, 10126, 396, 6289, 9214, 5114, 9056, 3193, 11420, 1562, 3702, 7135, 2784, 4692, 6520, 10938, 1328, 11383, 11498, 6322, 4209, 7514, 10206, 7730, 8387, 213, 5272, 9847, 9011, 8198, 3326, 6350, 5631, 8357, 8806, 12229, 3228, 7935, 3828, 12591, 1225, 333, 11826, 7046, 2837, 598, 6564, 120, 2239, 9074, 2683, 9828, 3750, 1292, 725, 12607, 7488, 6254, 7565, 2854, 2077, 3788, 6415, 4831, 455, 11364, 7843, 11215, 5275, 8421, 3897, 180, 3438, 2693, 10844, 3776, 8019, 555, 7254, 3518, 9195, 1924, 6493, 2578, 5606, 9019, 2777, 11539, 990, 7771, 434, 9121, 3428, 2988, 3045, 7711, 5053, 1717, 9482, 11133, 1579, 5607, 6216, 3169, 1576, 841, 4743, 2378, 1976, 12374, 2260, 3935, 2725, 249, 10083, 9565, 10780, 8893, 602, 3018, 12461, 9385, 8135, 11765, 12390, 7587, 9107, 12307, 3400, 9913, 9055, 7596, 7365, 9593, 1587, 5550, 1455, 4178, 6248, 8164, 1087, 9456, 9421, 10612, 1224, 8709, 7225, 5762, 6260, 1703, 3040, 5635, 10259, 604, 2771, 3347, 818, 6070, 915, 11352, 3895, 8472, 2494, 4356, 10653, 12067, 1641, 4272, 8487, 10026, 1021, 12097, 5591, 5048, 10, 9035, 3650, 2644, 10417, 11788, 6779, 9447, 8788, 1121, 7739, 5924, 9684, 1469, 9303, 3787, 4447, 4472, 4528, 6788, 3686, 3574, 4756, 116, 7394, 5801, 7333, 3866, 7352, 8723, 1899, 2286, 5810, 10878, 3652, 356, 12285, 2959, 3521, 7865, 10496, 3902, 3281, 916, 8365, 10176, 1126, 6438, 12039, 11115, 271, 7783, 2886, 9753, 8232, 1439, 5940, 3261, 6554, 11064, 4511, 6588, 1981, 251, 2606, 8168, 2938, 9649, 7683, 9946, 8451, 1822, 1212, 12434, 4746, 498, 8799, 7669, 387, 4912, 4095, 9525, 6395, 5296, 4940, 909, 1817, 6259, 3154, 4934, 2097, 556, 738, 537, 4852, 176, 8481, 7356, 1726, 4274, 12599, 10976, 1750, 2144, 10957, 8346, 1777, 11619, 11596, 2189, 10210, 4435, 3661, 9340, 11817, 10481, 4016, 888, 5532, 6602, 7538, 1837, 6199, 5451, 3081, 6653, 4130, 4099, 12018, 5769, 5739, 8550, 8681, 9442, 7882, 8059, 12485, 6211, 5092, 3190, 3831, 10861, 12290, 2680, 6966, 8906, 5709, 1950, 8747, 5043, 9207, 7757, 1367, 11898, 7256, 4817, 9644, 5700, 7552, 4324, 11893, 6927, 1030, 8881, 1527, 2860, 1966, 12165, 7595, 10340, 1044, 4414, 687, 25, 5236, 8415, 9082, 3957, 1095, 4751, 12372, 10480, 4282, 10821, 9638, 6615, 9347, 9249, 1369, 10775, 544, 7697, 4603, 5426, 10105, 11666, 5057, 9234, 4676, 10250, 8733, 10691, 10296, 9405, 3256, 3899, 4867, 460, 4507, 1132, 2410, 6021, 9398, 4800, 5506, 11394, 3755, 56, 360, 10130, 6772, 7898, 7369, 2019, 2242, 5268, 7126, 12005, 376, 3597, 940, 8173, 4740, 1072, 10889, 7660, 11384, 3644, 9437, 3285, 2258, 3466, 6046, 7075, 5208, 3355, 6891, 11768, 7569, 10104, 9102, 6414, 6342, 6798, 3576, 5674, 5496, 7381, 5687, 9544, 2801, 12162, 4453, 8949, 3973, 857, 2337, 5885, 1099, 8375, 9868, 558, 1738, 79, 11071, 6460, 5020, 2321, 4877, 6832, 7996, 12288, 2628, 2164, 4366, 3360, 4204, 4824, 12176, 10631, 4057, 1615, 2951, 10445, 12245, 8158, 9446, 5238, 2424, 7125, 4593, 442, 9784, 1113, 3243, 5972, 10824, 12624, 5896, 1116, 7827, 7918, 12025, 2440, 4413, 6621, 5608, 2617, 11060, 793, 3335, 6042, 4017, 8908, 11741, 5517, 12191, 2498, 2365, 2531, 2326, 5771, 8652, 4712, 9988, 6366, 12007, 11877, 2405, 7379, 6142, 2679, 108, 10504, 3493, 11139, 1381, 4876, 9471, 2868, 8204, 1141, 1075, 11612, 9892, 9673, 5394, 9261, 3848, 8749, 8024, 11004, 4926, 708, 5554, 4513, 8564, 2969, 9656, 7030, 10545, 8741, 10135, 2064, 5156, 11821, 11610, 3291, 6897, 11336, 6233, 781, 3748, 7090, 400, 5077, 600, 12287, 10066, 704, 8352, 2371, 10362, 6782, 7076, 4001, 9550, 2289, 5353, 2543, 3842, 2858, 2356, 149, 5144, 9576, 2783, 6241, 6294, 6732, 5673, 1498, 3035, 4313, 3055, 11163, 7238, 12058, 5578, 549, 2791, 11682, 6518, 1736, 449, 8259, 1868, 2696, 12171, 6777, 813, 6932, 5615, 4196, 9142, 401, 8865, 801, 10954, 623, 5065, 55, 2849, 9815, 12060, 7731, 11341, 12396, 12278, 6225, 4690, 3535, 11380, 719, 10908, 2040, 7022, 4416, 2627, 12392, 10519, 7011, 8185, 10222, 7856, 1922, 439, 7017, 7066, 5112, 2647, 6946, 5201, 1215, 6675, 7460, 3215, 9401, 8860, 12264, 9511, 8690, 4823, 5430, 10436, 7234, 898, 10634, 4726, 5524, 6445, 1313, 7399, 311, 10473, 8601, 5489, 8310, 12213, 7193, 5561, 493, 946, 9928, 5239, 5834, 8051, 10377, 197, 5429, 9991, 3005, 2805, 7464, 2692, 6562, 6607, 3161, 7302, 8866, 5872, 8212, 3187, 30, 5244, 2645, 6956, 5330, 12055, 1487, 4093, 4263, 9327, 7644, 126, 47, 7220, 5682, 5942, 2672, 3203, 12256, 1307, 1694, 6911, 12072, 4400, 5808, 6353, 3673, 4152, 8851, 4862, 9819, 2029, 9524, 344, 10301, 4071, 3680, 7906, 12301, 8953, 5751, 10010, 5154, 5117, 1057, 10324, 10454, 395, 9609, 6420, 1826, 9598, 11088, 8444, 5471, 2706, 663, 12605, 214, 7455, 5777, 10923, 6845, 5622, 7299, 9387, 10344, 6390, 10888, 2501, 10091, 3977, 6451, 9587, 10322, 8448, 5950, 7462, 3131, 6967, 4529, 7413, 10213, 11151, 10698, 688, 6170, 1697, 8879, 3158, 6408, 5215, 3201, 5645, 2044, 5552, 8662, 6535, 1244, 7436, 7905, 7183, 2049, 8738, 10287, 2904, 8796, 6457, 9911, 8028, 9788, 12174, 2887, 12216, 7453, 3765, 3969, 3327, 7442, 11512, 10353, 12289, 11107, 1921, 3540, 8868, 10404, 7603, 10611, 9098, 11544, 9138, 5336, 8579, 10920, 10368, 1291, 1825, 4214, 3900, 4939, 1859, 6281, 7873, 9894, 11408, 10466, 4856, 1961, 11220, 7539, 7665, 5147, 161, 8945, 7040, 3416, 3586, 3978, 10002, 1683, 4249, 12292, 2428, 8110, 10475, 4070, 7875, 10190, 5764, 2283, 4695, 9495, 4225, 5965, 8361, 3553, 7761, 8236, 12308, 639, 5835, 9650, 1990, 5791, 8663, 3494, 2764, 10236, 8306, 6896, 217, 4634, 3763, 10827, 2269, 4243, 722, 3502, 1917, 1443, 12022, 826, 3839, 6083, 756, 2327, 10913, 9479, 3020, 6096, 7601, 9561, 3260, 4153, 9337, 7598, 10510, 7385, 9635, 12249, 1628, 7239, 1858, 6656, 5194, 12417, 2998, 5439, 3059, 9545, 644, 4882, 5332, 11848, 1583, 11992, 5737, 7479, 11432, 6040, 6276, 2635, 6132, 5829, 8586, 877, 9386, 9518, 6137, 11529, 2586, 5994, 3736, 806, 4029, 12561, 10385, 5657, 8469, 10152, 10399, 12594, 12469, 8322, 361, 3437, 5464, 11932, 12190, 12116, 3847, 6662, 10831, 6857, 7511, 183, 811, 6266, 5536, 9884, 2513, 6150, 1004, 5407, 2510, 703, 10505, 9451, 10006, 12071, 4575, 10969, 7635, 5992, 1704, 9134, 9217, 1243, 10085, 4779, 8880, 10090, 3651, 1995, 6627, 7160, 11649, 6650, 6204, 6258, 7753, 7449, 10649, 11026, 12359, 10814, 9042, 5521, 7154, 3567, 3028, 6469, 5886, 1269, 1957, 109, 4577, 12044, 156, 6885, 1610, 7262, 7796, 696, 12101, 9818, 7210, 9574, 9534, 3417, 7176, 10239, 2577, 3391, 6391, 7315, 11441, 2426, 7588, 2561, 5168, 9984, 8599, 5007, 2661, 10233, 12343, 5614, 5933, 9435, 2264, 11399, 4790, 2011, 2665, 5254, 6448, 10748, 8489, 5858, 5893, 12384, 11412, 2460, 1972, 11677, 4468, 9790, 12028, 11340, 4022, 2716, 11971, 11318, 10557, 10898, 5763, 9203, 2667, 2298, 1180, 5747, 8443, 5094, 5442, 9685, 9480, 6368, 7437, 9854, 7461, 5259, 3006, 6912, 7790, 7002, 5182, 2593, 3274, 1034, 5707, 9302, 6626, 6715, 12295, 8869, 3324, 281, 3768, 11558, 12081, 11029, 11376, 7578, 10715, 5119, 3224, 6011, 10469, 8097, 6280, 10598, 7613, 9798, 5412, 5161, 10021, 12086, 12403, 2184, 9059, 12425, 9810, 7447, 1475, 4424, 5995, 3387, 1865, 952, 2454, 10763, 9950, 2111, 12228, 10787, 5805, 355, 1396, 1653, 6488, 589, 12203, 11632, 8961, 5691, 6563, 11791, 1385, 7367, 10376, 1410, 5643, 8467, 11714, 5317, 7799, 7591, 2622, 1728, 1202, 10470, 8828, 12181, 11660, 10820, 3565, 8095, 1846, 8544, 1608, 1626, 10009, 11298, 9066, 2217, 10041, 5305, 3367, 11093, 1894, 5036, 8699, 2312, 11566, 7360, 6900, 8798, 9844, 3685, 5247, 2464, 4570, 12481, 2766, 3312, 3443, 2551, 3909, 2875, 2232, 3626, 1364, 1913, 6253, 4074, 1619, 9874, 7149, 6743, 12209, 2612, 5901, 3603, 1020, 3024, 578, 3448, 1997, 4857, 2815, 3135, 2871, 1896, 12596, 3770, 6780, 7493, 2934, 4501, 8484, 8776, 12267, 11455, 6884, 1949, 1541, 4375, 340, 12145, 3069, 10764, 5934, 6060, 1589, 10257, 8706, 3365, 2638, 8170, 9300, 1739, 9191, 414, 5887, 8920, 8843, 432, 8314, 11179, 1176, 10048, 7904, 3125, 11867, 12619, 11360, 11597, 4942, 8301, 5400, 5035, 12275, 296, 11250, 9924, 4598, 4922, 11272, 10561, 12244, 11013, 5920, 3172, 11084, 6810, 635, 3517, 2468, 2415, 1245, 10509, 4657, 10558, 4418, 11988, 11409, 6731, 2832, 3852, 8536, 9949, 7829, 3479, 3103, 8809, 5646, 1300, 9559, 4491, 8291, 8470, 3181, 1659, 6222, 10426, 53, 6672, 9916, 10893, 1698, 8020, 4639, 8424, 9606, 517, 10699, 9194, 647, 9758, 4891, 2320, 4369, 5582, 5432, 10435, 8001, 5895, 9785, 8807, 4497, 2682, 1278, 10948, 9590, 10288, 1708, 4062, 11864, 9955, 11169, 1769, 8315, 7157, 10499, 10084, 866, 6296, 11527, 8530, 10413, 672, 8441, 10261, 9478, 1199, 9902, 11784, 6552, 5664, 8826, 9365, 8774, 11686, 9070, 6992, 6558, 5648, 2155, 638, 7811, 4011, 9212, 1652, 2504, 959, 561, 843, 12435, 3915, 5080, 1419, 9114, 5871, 1742, 3136, 11685, 12389, 10798, 2364, 9394, 3255, 4987, 3965, 2476, 9861, 12048, 6480, 5003, 4338, 5017, 10492, 8490, 1654, 1117, 150, 3608, 5741, 8944, 132, 7530, 695, 6557, 587, 2134, 878, 8886, 1960, 9427, 1157, 11488, 11510, 8979, 7810, 7986, 5108, 8853, 9376, 7270, 8649, 6153, 4000, 10271, 4630, 9782, 8590, 11363, 10223, 9202, 7435, 7897, 4201, 11175, 7617, 10312, 9431, 6108, 6003, 1832, 9245, 10302, 10132, 5356, 11983, 9614, 2467, 4595, 11603, 26, 368, 12489, 10705, 11871, 4806, 1128, 9470, 2990, 1425, 9969, 2241, 928, 1335, 11411, 1242, 1871, 797, 6378, 8141, 5792, 2353, 336, 12456, 10522, 11131, 1347, 3017, 10160, 5197, 12031, 11112, 6453, 6311, 2060, 8311, 3983, 7695, 1591, 9802, 11587, 6707, 6931, 8770, 440, 9367, 492, 5780, 9166, 8410, 2900, 9786, 5281, 2733, 6781, 4686, 2277, 12161, 12466, 8295, 8661, 10766, 7885, 9295, 101, 6679, 2507, 10361, 9776, 11890, 11320, 9409, 7259, 10771, 4671, 2098, 7614, 4425, 4270, 3065, 228, 5100, 11194, 9751, 11531, 7619, 10701, 9612, 9000, 7190, 9315, 347, 1650, 1326, 11502, 3556, 3593, 5498, 8304, 10221, 457, 11381, 3010, 3132, 4796, 12310, 8654, 1149, 7863, 863, 9709, 3860, 426, 7701, 12260, 10542, 9096, 7654, 6175, 536, 4024, 10572, 9108, 10265, 577, 4397, 1666, 11986, 11925, 8842, 2736, 5713, 10992, 9196, 7914, 626, 4059, 4953, 617, 6094, 8456, 5328, 6726, 3579, 119, 993, 6349, 11667, 4597, 6847, 12120, 5082, 939, 5437, 8139, 10963, 3649, 9165, 6817, 10794, 2288, 4512, 3458, 10868, 5314, 6473, 6376, 1389, 1635, 31, 8376, 3746, 8898, 6115, 4619, 12202, 4357, 10708, 5187, 1554, 1664, 9886, 2911, 817, 2113, 6341, 3962, 734, 4171, 5832, 12402, 5873, 1344, 6187, 9206, 8997, 11201, 1744, 12085, 174, 8676, 4145, 4655, 1184, 9465, 10851, 1002, 11514, 10823, 4002, 7845, 9567, 11327, 8297, 4762, 10979, 338, 8406, 6035, 5958, 7962, 7734, 9378, 9428, 7120, 11198, 9269, 8476, 6522, 7366, 1465, 8616, 3029, 4486, 12159, 9764, 2344, 11227, 2482, 9675, 7563, 11951, 8221, 5383, 9371, 11128, 10321, 5284, 4543, 1892, 12008, 4802, 11533, 4994, 3580, 8196, 3307, 7866, 9257, 6162, 8794, 4970, 8142, 2658, 6127, 2584, 11645, 3167, 2389, 10227, 1, 1493, 575, 6470, 2608, 8224, 5862, 2412, 5428, 9799, 7226, 1276, 9077, 5478, 12002, 8294, 11080, 8987, 12073, 5245, 2483, 12143, 11785, 1039, 2499, 11614, 7820, 9258, 11759, 11495, 40, 7775, 12381, 484, 5856, 641, 5721, 6515, 1197, 2810, 1908, 4258, 3315, 8679, 2281, 4866, 979, 8374, 10434, 8595, 2081, 8558, 6874, 4311, 9383, 11786, 729, 7802, 10076, 7328, 12009, 5023, 7015, 427, 11208, 2102, 7589, 2012, 3252, 9473, 7263, 2646, 4959, 2181, 9198, 4975, 441, 11354, 2128, 3515, 11792, 9348, 3734, 51, 11671, 3901, 8673, 3936, 10391, 9466, 443, 6519, 1795, 9324, 8639, 2648, 5252, 2110, 9531, 9242, 10388, 410, 6840, 5503, 10199, 4566, 3271, 7219, 5617, 3822, 718, 10479, 5297, 2991, 2912, 1435, 424, 6628, 10448, 9002, 9648, 10675, 6177, 4648, 12615, 10554, 1289, 9476, 5571, 8695, 10318, 3173, 1937, 5720, 5500, 1094, 6381, 7688, 5301, 9301, 6647, 661, 8680, 7415, 5587, 2259, 2046, 3450, 4200, 5743, 5960, 1426, 9608, 9543, 5203, 512, 5329, 10935, 11387, 4795, 10397, 8434, 6770, 12262, 827, 4295, 5415, 11181, 10166, 10110, 8567, 10646, 2859, 9308, 4033, 1061, 2456, 8716, 3785, 7137, 209, 9927, 4126, 11073, 5320, 10783, 651, 9853, 9960, 4787, 1486, 8918, 476, 1840, 1370, 6669, 3913, 238, 417, 11283, 1190, 5481, 91, 7044, 4482, 3176, 8592, 1782, 3530, 12212, 8013, 7763, 10025, 1445, 6374, 9486, 2928, 2314, 9838, 2452, 621, 12467, 8904, 11317, 533, 12533, 8874, 4899, 9957, 11844, 9133, 2803, 552, 8877, 1743, 3953, 7912, 2250, 9397, 4322, 6930, 4642, 3737, 9917, 12524, 10549, 4977, 252, 179, 2575, 11, 12153, 11403, 1791, 3304, 479, 3700, 2120, 11240, 11839, 1757, 12111, 4659, 1274, 5286, 7179, 4459, 3808, 591, 2634, 10439, 6061, 874, 9057, 9858, 2848, 11126, 4636, 7444, 8393, 5125, 6279, 9090, 9459, 10741, 11279, 11975, 2028, 10380, 11699, 5510, 7515, 1164, 6719, 8225, 1596, 1624, 10945, 5945, 11841, 9455, 7480, 1785, 3341, 3987, 10788, 11419, 3313, 8545, 3483, 11342, 1895, 10329, 1986, 9630, 625, 12017, 1614, 5376, 9752, 7672, 5699, 8280, 11959, 8528, 11177, 2471, 5370, 3221, 1350, 11224, 9410, 6210, 11957, 6352, 6765, 7961, 11824, 4475, 3461, 4434, 6791, 11461, 10782, 1888, 4179, 4674, 539, 1546, 144, 11638, 9260, 4624, 9227, 11478, 4392, 2185, 6681, 7266, 10063, 3628, 7345, 6630, 2691, 2739, 567, 10925, 7957, 6922, 6206, 12049, 8959, 9582, 475, 4641, 12623, 4771, 5999, 8199, 12521, 3336, 3445, 7337, 3137, 6698, 11882, 1669, 4464, 412, 2809, 7528, 6382, 9370, 8787, 12526, 8588, 5847, 10865, 2961, 7917, 11135, 8148, 4809, 90, 6584, 11490, 4519, 226, 10895, 1270, 7459, 1771, 11769, 6475, 6077, 7230, 8150, 1424, 5973, 656, 12617, 10603, 4188, 10410, 1571, 5683, 4055, 10107, 9872, 9522, 3782, 11673, 7663, 6612, 9464, 7702, 1167, 3997, 5448, 6841, 6676, 11011, 9021, 3672, 233, 2788, 18, 11235, 4285, 10284, 8966, 12279, 7006, 10718, 7717, 6551, 6935, 4578, 566, 879, 4122, 1070, 8119, 1472, 3329, 4958, 12242, 2971, 1143, 8707, 6194, 12170, 2432, 7584, 5970, 7312, 7953, 10754, 10725, 6058, 6119, 6091, 114, 6191, 9512, 2387, 3891, 11055, 5192, 8587, 6591, 2160, 1483, 11143, 1146, 6751, 2141, 1716, 12239, 5722, 9322, 7151, 6255, 7331, 8858, 11023, 9915, 8632, 611, 1208, 10319, 7767, 6059, 9681, 613, 5262, 1861, 9719, 1340, 11292, 5274, 2625, 2847, 5542, 8130, 6339, 3658, 7119, 3404, 3759, 10358, 8215, 7679, 3812, 4997, 7308, 12151, 6668, 6831, 11160, 454, 1715, 6090, 845, 4974, 92, 12429, 4890, 2741, 2066, 5431, 1254, 9413, 12091, 8560, 3625, 10877, 8767, 12121, 3093, 6853, 3358, 9363, 9274, 7694, 2954, 6894, 5418, 8339, 9361, 5911, 6397, 12032, 1753, 1152, 6495, 4129, 7762, 9097, 2014, 6822, 1971, 8200, 6229, 2458, 10495, 12014, 5817, 6298, 5959, 4044, 10882, 12350, 9316, 12406, 1025, 9860, 7764, 9848, 8844, 12620, 12078, 6876, 8575, 97, 5368, 4385, 10833, 5470, 7391, 11691, 7828, 6690, 746, 3286, 7096, 3441, 7890, 11157, 1407, 10854, 3102, 11211, 11147, 2118, 10416, 8548, 8650, 2278, 4287, 3534, 1706, 6036, 9723, 6836, 10620, 10852, 8334, 10585, 7579, 1405, 11268, 8726, 9094, 6849, 1096, 5997, 2772, 3709, 4079, 10089, 8417, 4405, 461, 3382, 11905, 309, 12379, 905, 2979, 601, 3174, 4154, 8288, 5818, 2131, 7363, 8822, 6407, 8645, 10606, 10077, 6428, 11995, 6569, 2078, 4289, 8372, 6601, 9285, 7189, 10007, 5344, 1082, 8542, 774, 4094, 5, 1862, 8576, 8460, 11324, 6964, 12113, 4938, 3130, 4340, 3350, 5066, 664, 6800, 8786, 7303, 2032, 9842, 9721, 9342, 11074, 185, 11395, 5209, 41, 3235, 2695, 6708, 5337, 5760, 8010, 2609, 3303, 3343, 11626, 3552, 3209, 3455, 9733, 11930, 1564, 2121, 2999, 7512, 11358, 12464, 8783, 10273, 9891, 10559, 11377, 2247, 11037, 3340, 8964, 7956, 253, 8064, 11990, 4476, 6754, 112, 11274, 11132, 582, 10036, 1504, 7993, 187, 3430, 3216, 11265, 7208, 2368, 5061, 11102, 7136, 2075, 6943, 1580, 12322, 2082, 9826, 9235, 10912, 11156, 1494, 2945, 3402, 9467, 6739, 9010, 9716, 2045, 8341, 580, 3356, 7316, 619, 1194, 4533, 7954, 390, 6598, 2497, 10660, 6808, 6022, 5585, 6575, 2188, 11447, 10277, 11413, 6695, 1234, 2843, 1860, 2472, 7104, 4362, 10120, 4992, 8197, 3310, 12118, 4293, 9774, 684, 2435, 5984, 4166, 3423, 1723, 4544, 5380, 992, 8023, 12312, 11847, 10128, 8331, 9633, 6825, 9871, 4128, 9126, 3409, 2957, 9346, 4615, 1142, 7568, 7204, 12193, 7721, 7284, 6843, 11184, 7759, 4183, 542, 7910, 1600, 1627, 1287, 9653, 11650, 4724, 6597, 7185, 4582, 8670, 473, 3594, 7325, 8167, 8281, 2071, 1218, 10403, 2546, 2506, 8183, 10095, 8725, 1902, 3442, 7298, 6304, 8664, 3301, 4463, 8895, 5355, 11513, 7719, 2374, 5360, 4334, 7648, 9462, 5533, 302, 3278, 753, 2306, 6929, 6644, 5650, 8070, 2599, 10972, 10124, 5138, 6566, 8643, 1886, 10305, 7989, 8708, 5120, 6020, 11482, 5257, 8921, 1252, 5563, 7139, 1685, 1974, 11234, 3198, 10147, 416, 7709, 10728, 2717, 9586, 7003, 5880, 2193, 4137, 796, 14, 6816, 8062, 7902, 9356, 1362, 1342, 227, 59, 5258, 4983, 987, 4549, 12273, 11314, 3033, 614, 6901, 8633, 1402, 1193, 11701, 6561, 507, 8711, 994, 11953, 4908, 9448, 6084, 1086, 3653, 1745, 6295, 3418, 8509, 11543, 1334, 6981, 1585, 7948, 2660, 11137, 10797, 5220, 2744, 10630, 12084, 5157, 22, 9505, 6870, 2005, 1159, 10936, 12243, 11578, 5414, 4538, 8627, 840, 6440, 7901, 4182, 12437, 4254, 9208, 12253, 9985, 3961, 8102, 6189, 3998, 7509, 261, 1353, 2699, 5175, 9046, 11549, 6471, 4352, 2604, 12342, 6245, 737, 5519, 6283, 3827, 8722, 3996, 10655, 9639, 9951, 1761, 7252, 4798, 10332, 7554, 2291, 7439, 8078, 5625, 11154, 4730, 3468, 1296, 11434, 524, 8885, 9912, 6103, 10468, 3272, 771, 8006, 2194, 9952, 3411, 10553, 10446, 2749, 4737, 5501, 11196, 7649, 69, 7211, 586, 6312, 5736, 5926, 1905, 3213, 6161, 9611, 7618, 2301, 10098, 11454, 3269, 4279, 8055, 8256, 2152, 6567, 8216, 9971, 9877, 4135, 5605, 6340, 9856, 1092, 8430, 2562, 6807, 6706, 7402, 11000, 448, 10536, 4669, 2778, 3715, 5218, 11670, 3200, 10345, 10808, 11393, 7943, 677, 9619, 5032, 100, 9834, 7383, 7576, 10122, 4330, 10149, 2774, 3507, 3379, 8500, 1298, 8941, 9272, 11063, 4236, 12442, 4457, 1110, 11438, 11350, 7100, 3793, 9873, 7361, 9995, 9767, 2123, 7816, 5666, 3183, 5881, 1187, 6792, 9400, 8882, 2004, 11325, 5241, 11615, 2637, 7227, 3558, 9127, 1891, 7886, 9849, 7853, 6389, 9252, 1027, 10200, 8329, 3275, 2989, 2697, 2850, 178, 1314, 11758, 6496, 4050, 2756, 5694, 2108, 12339, 11688, 7342, 3620, 2595, 11101, 5311, 5494, 5095, 4870, 3890, 4995, 2557, 2814, 10674, 8830, 6, 1271, 10381, 12196, 5541, 1762, 4315, 8237, 9211, 1879, 2924, 11698, 2409, 1660, 12298, 5693, 304, 366, 7541, 6455, 9604, 10458, 3266, 1595, 8705, 451, 2564, 8870, 3254, 8242, 4364, 10590, 1479, 11189, 5857, 1629, 3211, 9705, 6165, 4401, 12184, 1012, 7117, 2430, 3679, 357, 11966, 8459, 4318, 63, 12618, 933, 5888, 5386, 6753, 6178, 9626, 7008, 11504, 654, 6960, 7872, 2686, 10809, 3034, 7438, 5172, 2675, 675, 1926, 11271, 12580, 10803, 10773, 4417, 5688, 5366, 8388, 4257, 11367, 45, 11782, 6594, 11873, 2949, 9643, 1077, 1013, 7781, 7141, 2335, 965, 10350, 2916, 7637, 9594, 10768, 4325, 5864, 11999, 2597, 6249, 1531, 1930, 12023, 6978, 4107, 8985, 7064, 7434, 7026, 8068, 2235, 3682, 3583, 1089, 6875, 10752, 7941, 2165, 12198, 4561, 10395, 6649, 7548, 11302, 4003, 1482, 7804, 9583, 798, 6160, 5611, 6559, 2836, 9863, 1301, 7656, 4664, 8133, 10429, 4247, 5704, 4253, 5071, 5398, 6268, 4687, 6498, 6499, 11997, 2163, 471, 3016, 5318, 4170, 11141, 3814, 2923, 11114, 3810, 11249, 5287, 11275, 7519, 12182, 8336, 12457, 11423, 7296, 7212, 9809, 7939, 3189, 1365, 882, 2061, 9069, 12492, 3115, 1661, 4019, 1538, 3293, 6991, 3230, 4444, 12215, 10588, 6158, 12001, 5025, 9374, 8025, 3951, 11582, 10449, 9254, 6760, 2929, 8743, 7916, 6809, 4439, 622, 900, 5260, 6972, 7215, 9850, 11643, 7264, 2253, 4886, 10678, 7387, 2348, 3426, 12629, 7323, 10952, 10197, 8140, 11889, 62, 830, 10393, 2474, 7249, 10401, 9570, 11009, 10966, 2296, 10065, 5520, 10982, 4494, 2173, 10327, 1772, 3865, 7019, 3121, 2138, 1235, 11904, 171, 9299, 3857, 7281, 3771, 2207, 7959, 7330, 669, 12328, 2007, 3060, 8571, 4008, 9038, 2052, 9888, 6324, 11415, 7065, 5325, 2711, 6369, 7536, 4973, 398, 11468, 8933, 6458, 8720, 7700, 5629, 11042, 2251, 10565, 9597, 4337, 1232, 12235, 242, 9463, 8955, 5231, 10022, 10441, 8990, 6531, 5204, 495, 2898, 7128, 8519, 10757, 11697, 10848, 6018, 5962, 5849, 11674, 250, 519, 9423, 8801, 6303, 4104, 6919, 3543, 2054, 4707, 8247, 12583, 12026, 5565, 8399, 4793, 8015, 5964, 4810, 3636, 3146, 6406, 4804, 4667, 2536, 3799, 10205, 8003, 10977, 5874, 11618, 12576, 3705, 4965, 4719, 8813, 5564, 2910, 4903, 10804, 11827, 12424, 1575, 5698, 10462, 7062, 11051, 765, 9707, 510, 11861, 3669, 2038, 2220, 4266, 8190, 5861, 4142, 2183, 583, 1168, 4541, 409, 3043, 1214, 12625, 9703, 11426, 8861, 5516, 1029, 4004, 3720, 1945, 835, 5535, 1919, 8744, 1934, 5235, 11027, 10201, 11795, 5575, 9032, 2585, 11815, 7122, 7623, 2508, 1681, 8482, 8454, 4396, 223, 1701, 5641, 8088, 2397, 7560, 7140, 7833, 95, 8442, 2070, 4224, 4127, 11956, 5619, 7334, 4679, 9323, 3346, 10896, 1223, 5460, 6411, 5656, 12088, 75, 1674, 6633, 3871, 10402, 8254, 596, 7487, 9513, 12585, 1227, 5316, 10548, 6398, 4904, 3664, 12135, 5529, 2768, 4403, 1702, 6955, 1266, 4805, 11501, 5173, 8902, 11964, 9496, 10749, 6181, 7317, 1374, 7661, 10387, 3940, 9882, 6786, 2639, 3703, 5867, 7241, 9407, 12584, 6553, 8605, 897, 5391, 4917, 4928, 9151, 2747, 10453, 1590, 9568, 3292, 9419, 6998, 42, 12488, 3250, 5099, 1824, 4957, 4955, 8589, 8396, 11152, 2073, 2888, 876, 8318, 2516, 11522, 8257, 6063, 11285, 1306, 8285, 4084, 8792, 3234, 1776, 4772, 7545, 3611, 2730, 8980, 4391, 6230, 5086, 1329, 6902, 8593, 3413, 8512, 6215, 3867, 11405, 11616, 3912, 8756, 5105, 6572, 4614, 12504, 380, 11245, 7082, 5930, 8889, 12173, 67, 2678, 2496, 9453, 8056, 10801, 10840, 6508, 1954, 322, 3328, 9029, 11375, 1123, 3844, 7071, 4778, 4245, 3975, 9820, 5943, 8504, 5306, 8045, 10335, 125, 3004, 6696, 11061, 1026, 1530, 7474, 3792, 6430, 4039, 4720, 4117, 11500, 751, 964, 5403, 10103, 11456, 199, 5131, 12261, 3401, 4927, 5990, 8856, 6643, 3244, 7432, 9311, 3202, 7881, 9283, 12226, 7491, 6724, 2909, 5224, 7638, 6500, 7497, 620, 7958, 9238, 3835, 478, 8081, 3967, 2935, 3744, 9364, 7086, 3832, 5487, 6377, 2136, 8462, 2745, 1655, 6436, 10411, 4801, 3152, 6763, 9691, 4828, 4262, 7080, 10331, 7571, 3412, 4947, 5190, 10546, 3570, 4286, 7615, 9420, 12154, 1042, 10600, 1371, 1758, 9354, 844, 1867, 9321, 6511, 10113, 4505, 11598, 7990, 7797, 1637, 2568, 10555, 7180, 3498, 9351, 5509, 9769, 4231, 11892, 9224, 4789, 12353, 7456, 5064, 7371, 7684, 9155, 4061, 10168, 10244, 1567, 11845, 6476, 800, 3927, 102, 503, 6155, 8057, 10807, 10137, 4632, 6965, 6988, 11172, 9122, 3952, 2946, 12413, 11538, 11466, 12175, 9241, 11338, 10438, 7301, 3062, 11090, 10193, 10164, 3667, 3082, 5181, 11858, 8380, 8364, 481, 1016, 12382, 8143, 4881, 10024, 6000, 8368, 4269, 2169, 7109, 4936, 12509, 5256, 9624, 7778, 8252, 7668, 1174, 6939, 3267, 5477, 1780, 4096, 776, 9231, 4998, 3481, 7769, 2000, 8892, 1236, 10303, 4460, 10373, 4248, 8085, 5748, 3888, 10774, 1456, 10587, 11448, 10235, 9209, 9392, 11185, 6099, 2240, 3191, 5421, 6013, 110, 7662, 8046, 11424, 11836, 8475, 7177, 8672, 10493, 142, 4294, 11602, 2899, 7580, 8940, 4359, 11604, 10745, 1606, 9003, 4147, 7061, 3601, 9591, 1603, 4906, 6962, 8313, 2655, 11634, 1348, 2795, 12538, 12460, 6043, 10654, 8394, 3376, 111, 3596, 4361, 4617, 10181, 7314, 5453, 11900, 7178, 4542, 35, 29, 9441, 8123, 5040, 8032, 6130, 9585, 11780, 10779, 5768, 6963, 4803, 7079, 3496, 11563, 8597, 8608, 3716, 4426, 8426, 4450, 3537, 2332, 12223, 3175, 12550, 4716, 7746, 8704, 3881, 9366, 24, 10467, 5675, 11589, 5756, 6828, 8935, 12554, 12494, 4316, 8522, 11435, 12484, 6098, 4049, 1645, 837, 2056, 12393, 9281, 4591, 4527, 1690, 1414, 9663, 8570, 11881, 2186, 2712, 6173, 6513, 10226, 2050, 3566, 9631, 3217, 3643, 11532, 10967, 335, 2486, 11773, 9792, 10886, 11981, 1773, 1316, 775, 8370, 9530, 5586, 7240, 1713, 2512, 7025, 8755, 3930, 3893, 64, 8298, 1127, 11998, 2775, 7624, 10125, 6041, 4052, 11254, 10696, 1537, 2615, 5628, 9824, 9255, 4728, 436, 10997, 282, 11721, 2231, 2375, 1463, 511, 11725, 8091, 12331, 9167, 9578, 10447, 4465, 8795, 10430, 8207, 5135, 10881, 861, 881, 1084, 7860, 2767, 1318, 5860, 6465, 8922, 1151, 7108, 4111, 2737, 9170, 3164, 6432, 7466, 5980, 4579, 11233, 3039, 12519, 6163, 7581, 8171, 6507, 10958, 7692, 66, 4305, 5013, 4101, 8079, 1747, 8384, 7161, 971, 5008, 9808, 3589, 4863, 6014, 4180, 2652, 7236, 4300, 9113, 7594, 10664, 5230, 11385, 12611, 5309, 7557, 2981, 11307, 1755, 1135, 6338, 2834, 2465, 11203, 764, 3767, 1787, 11592, 5492, 4389, 9908, 6125, 6767, 10145, 5178, 7243, 1261, 8420, 3766, 783, 4080, 11886, 6579, 3910, 12482, 2763, 8789, 7429, 7012, 8446, 7924, 3968, 2787, 3333, 4651, 1774, 2272, 2266, 10759, 4588, 4752, 9690, 198, 10849, 3786, 11323, 12385, 4068, 3805, 9445, 7147, 6447, 6539, 6354, 8624, 700, 848, 12397, 8033, 9617, 804, 5527, 4665, 7784, 6611, 12109, 9729, 6834, 7403, 5009, 8188, 3148, 12329, 5141, 9156, 824, 1731, 2890, 3523, 5976, 9181, 3928, 6055, 4438, 10097, 4989, 9131, 7735, 2816, 8162, 3616, 5072, 10118, 6045, 7923, 9890, 5504, 2246, 7857, 3503, 9959, 8117, 3618, 8345, 6394, 8574, 10106, 3117, 2828, 6224, 7549, 9832, 731, 10899, 2059, 1391, 3296, 7894, 2723, 8320, 8934, 11475, 11096, 10964, 1386, 11621, 2671, 6235, 3002, 1830, 3712, 5644, 9800, 1345, 10314, 9875, 6180, 262, 627, 11246, 522, 7353, 11798, 6996, 4773, 1805, 1476, 10835, 8317, 11724, 2492, 4077, 4522, 8719, 4884, 12495, 12158, 7441, 8848, 5397, 785, 12247, 2091, 10538, 1543, 2391, 7964, 4378, 12370, 3457, 9273, 6510, 631, 4981, 7999, 1550, 9726, 5438, 8026, 1549, 10815, 562, 6787, 11684, 9179, 12136, 8274, 11260, 11494, 235, 5310, 8759, 6747, 10117, 11912, 6364, 4443, 2388, 10643, 12250, 12227, 3629, 11508, 2411, 7351, 12545, 4423, 7485, 11931, 7553, 6694, 4732, 6940, 11807, 3794, 3452, 10729, 8629, 5875, 6722, 5088, 2879, 11556, 11439, 2997, 2742, 12324, 1154, 482, 9076, 4558, 4036, 1923, 2891, 8718, 5484, 2976, 6646, 4230, 7817, 652, 2084, 9132, 12240, 7095, 8884, 3239, 8740, 3692, 5983, 7037, 1799, 5443, 3075, 2009, 7889, 6969, 7346, 2919, 5613, 12257, 10984, 8342, 12502, 8900, 10183, 3149, 8647, 7630, 7124, 9528, 4608, 5246, 11530, 7068, 4069, 12069, 9682, 5185, 11907, 11568, 4034, 12563, 2995, 4585, 5459, 1719, 2016, 5472, 9623, 2687, 10203, 7292, 8873, 1303, 6544, 12230, 773, 836, 3645, 11651, 1006, 4312, 590, 4037, 5307, 4504, 9267, 723, 10697, 4047, 145, 12234, 3956, 8112, 1203, 6023, 5658, 10494, 8534, 1440, 4948, 4754, 2804, 11351, 4562, 8155, 1788, 11717, 9418, 11802, 5408, 10333, 1875, 8457, 2670, 11345, 10781, 1277, 9106, 11089, 12062, 10839, 7944, 9992, 7505, 7970, 10596, 9661, 12590, 1454, 3317, 1312, 6864, 5727, 2663, 7039, 10216, 11509, 10293, 3801, 4532, 5797, 8125, 5595, 9701, 4966, 10648, 7551, 4336, 1114, 10695, 293, 516, 7412, 9089, 7928, 5957, 7840, 4309, 11973, 12368, 12237, 4388, 2212, 3690, 4844, 8975, 9562, 5229, 4211, 4943, 1090, 6691, 2446, 11554, 2162, 290, 1696, 10444, 8847, 6404, 3330, 12532, 4410, 4677, 3886, 11546, 3157, 7626, 8389, 4888, 5549, 2835, 4684, 4408, 6002, 7409, 2176, 8820, 6079, 11103, 5620, 9603, 662, 3415, 6505, 9329, 7607, 4865, 264, 8000, 9907, 8041, 2621, 5785, 4838, 8611, 11371, 1699, 9287, 6282, 12099, 11391, 691, 10921, 10607, 8452, 4760, 2903, 11706, 12608, 8897, 9103, 245, 1377, 6065, 782, 2605, 6085, 11633, 4879, 5242, 11105, 6677, 1929, 3914, 2594, 6949, 3231, 12373, 2598, 12595, 9899, 11665, 8685, 7590, 4518, 8038, 3721, 5719, 1088, 2914, 3151, 6619, 5685, 5577, 8978, 11669, 3743, 11952, 9222, 3056, 8359, 6818, 205, 8502, 6416, 2895, 8416, 712, 12040, 5085, 709, 9628, 991, 3134, 1559, 10885, 462, 9020, 12139, 9216, 9795, 3714, 5142, 551, 9244, 292, 8118, 11108, 12186, 10237, 5300, 8324, 1336, 9655, 8037, 10407, 8377, 7516, 2457, 3933, 2893, 8677, 8065, 6547, 842, 2095, 2581, 3911, 7934, 257, 1834, 3475, 49, 12453, 1528, 10017, 1155, 5291, 11116, 5056, 5559, 5633, 1272, 11331, 71, 7791, 11304, 6670, 4136, 4976, 6313, 7854, 4932, 7340, 1331, 1783, 10524, 632, 8411, 1598, 4395, 8810, 7879, 3150, 5988, 5303, 5750, 2112, 4445, 3398, 5710, 7218, 10574, 12361, 2030, 6379, 10990, 8226, 3090, 8100, 191, 5899, 4323, 4673, 3143, 8124, 4146, 890, 865, 1521, 3718, 7242, 12270, 9449, 10769, 9622, 11113, 11736, 2913, 5476, 4930, 10978, 7825, 7106, 11585, 5772, 270, 7788, 12358, 2485, 4116, 963, 9527, 10179, 4755, 12493, 9743, 12211, 5686, 5939, 6417, 2216, 4273, 2881, 3562, 7859, 12076, 1680, 1169, 12347, 9187, 3373, 2300, 12265, 6714, 4064, 4174, 148, 5784, 3500, 11820, 11869, 11899, 8808, 5804, 7723, 9180, 9414, 124, 10039, 1594, 7396, 8305, 2105, 10339, 6503, 10866, 7213, 10755, 693, 7454, 9026, 10762, 5425, 11517, 2252, 10685, 11053, 2104, 11663, 11853, 4711, 4141, 5618, 12418, 3883, 2824, 6490, 9120, 4729, 11750, 10618, 1109, 1733, 10777, 1293, 9746, 11261, 10060, 3022, 5002, 7034, 11804, 9119, 1264, 7118, 3229, 9149, 8004, 6143, 12221, 795, 1778, 4509, 10465, 3587, 1611, 11452, 234, 8436, 3241, 9183, 5219, 4433, 6869, 2590, 871, 5160, 10281, 10378, 9221, 175, 2659, 8251, 2915, 7855, 2855, 3917, 11866, 2094, 8713, 2517, 1273, 1014, 12571, 11855, 305, 3186, 8937, 82, 9510, 7, 1102, 241, 2092, 8691, 8835, 12542, 5444, 12527, 5661, 327, 8149, 10243, 37, 7131, 3617, 8493, 4427, 3432, 5312, 3632, 10610, 3854, 822, 3262, 11757, 9948, 10802, 4626, 9024, 6774, 6087, 7871, 1376, 5123, 6617, 11312, 3525, 4219, 4568, 128, 7707, 4645, 2346, 8253, 12463, 5364, 190, 27, 12305, 5723, 670, 7498, 9734, 3361, 4540, 1946, 11735, 6709, 321, 10364, 11794, 11516, 7556, 4945, 6169, 2792, 6867, 10412, 1705, 5672, 8688, 1931, 10944, 6509, 8260, 5738, 650, 2208, 2377, 8083, 6492, 7642, 7424, 6328, 34, 365, 4580, 1838, 5837, 7392, 7768, 11760, 2338, 4411, 11704, 10043, 11470, 12098, 568, 453, 3850, 5742, 5054, 10624, 8121, 657, 7625, 10858, 9601, 5955, 6074, 3348, 11244, 9468, 910, 3424, 11710, 11574, 873, 6212, 9803, 1432, 11404, 3030, 1256, 8447, 6335, 870, 6778, 8598, 10719, 10941, 10711, 1763, 3113, 685, 4374, 4713, 11359, 10238, 10363, 2190, 9310, 6889, 1552, 12282, 4237, 2074, 2524, 5987, 11552, 9399, 2690, 9487, 9964, 5266, 2933, 7770, 3695, 277, 9641, 8836, 346, 6729, 8111, 2982, 1393, 12548, 2407, 10579, 7610, 4168, 3021, 7206, 6592, 10860, 12443, 4699, 4761, 9646, 1686, 10670, 12080, 5537, 6861, 6918, 1354, 1489, 5952, 4181, 8911, 7103, 5290, 9851, 2201, 5404, 7041, 1621, 7655, 2776, 210, 9806, 3227, 1617, 9406, 3775, 4483, 1607, 7115, 10081, 1557, 7446, 3316, 5177, 7198, 8960, 2808, 11418, 4090, 4895, 9761, 10672, 12117, 2027, 8760, 8620, 6302, 2689, 8302, 8018, 4898, 1553, 10428, 11884, 4284, 7818, 4814, 8899, 7430, 8689, 1548, 11938, 5515, 7490, 9123, 10613, 1437, 4023, 9708, 2089, 2651, 12126, 10998, 7224, 85, 1341, 6749, 6136, 1438, 11590, 11753, 8391, 9416, 2083, 1080, 8128, 8561, 6842, 5468, 12178, 6856, 7376, 667, 9523, 12468, 2908, 10740, 2574, 6012, 3460, 6107, 7540, 1299, 1566, 2010, 6727, 10818, 5966, 11742, 5807, 1130, 2349, 3318, 748, 6938, 12074, 6925, 4072, 8800, 12056, 2447, 8449, 5598, 3526, 6773, 2535, 7742, 4083, 7358, 9989, 6908, 7558, 2939, 12513, 4402, 726, 7440, 2072, 2844, 9012, 10581, 2228, 758, 12218, 4437, 860, 1103, 9111, 383, 5347, 6066, 11206, 1983, 1418, 2896, 4488, 6634, 10119, 4081, 267, 2582, 3665, 743, 6742, 7933, 4351, 3383, 2553, 11259, 8392, 8404, 12498, 4246, 10867, 574, 9493, 216, 10405, 4920, 10560, 12546, 6357, 2143, 88, 1514, 1814, 10901, 12400, 564, 6220, 4923, 7506, 1804, 8299, 12254, 9738, 117, 5324, 3270, 2214, 5567, 11015, 7535, 407, 5534, 12411, 4984, 10758, 4727, 6450, 8262, 10191, 4554, 4210, 6744, 5067, 553, 8948, 10073, 4833, 5528, 750, 10136, 4996, 4944, 10905, 10790, 9352, 12367, 372, 9450, 397, 12122, 8914, 11162, 10154, 12015, 11813, 12474, 8764, 12371, 5573, 4394, 1947, 9897, 10515, 3451, 273, 7144, 7338, 6827, 7878, 5029, 3188, 11970, 1366, 8520, 1843, 5731, 10459, 7253, 2779, 10396, 9178, 12160, 7501, 780, 9932, 7546, 8523, 8915, 4600, 7874, 988, 1973, 8698, 10902, 10996, 9781, 514, 8737, 10150, 7801, 1320, 6156, 8999, 8773, 10275, 10172, 5001, 10082, 7806, 11908, 12612, 8201, 6529, 885, 4215, 8555, 2178, 1022, 10153, 7191, 4739, 3031, 4704, 5923, 7377, 546, 3011, 11564, 8811, 6651, 9491, 5189, 12104, 3678, 6883, 12447, 10566, 2229, 160, 1019, 6768, 8248, 4250, 9312, 7018, 6068, 1794, 10133, 8872, 5843, 12016, 7946, 7722, 716, 2614, 445, 7758, 7181, 6246, 8403, 7658, 4583, 8603, 12503, 8984, 1827, 8153, 6944, 5143, 3225, 1098, 11110, 11851, 5884, 7182, 10943, 3554, 12041, 9627, 3112, 9022, 11716, 11264, 856, 6326, 6758, 7093, 4587, 7867, 7248, 2571, 12562, 10871, 12138, 951, 4666, 11187, 4066, 1662, 3918, 4185, 9855, 5359, 7627, 5891, 10518, 8463, 3433, 6050, 3240, 3642, 7335, 12500, 1884, 3247, 833, 6237, 10463, 256, 11348, 5079, 10834, 10813, 5188, 7653, 9377, 1912, 9193, 10032, 7389, 12523, 2872, 5075, 6723, 11989, 4843, 6008, 7715, 7089, 12387, 1823, 8390, 10592, 5377, 2324, 2043, 9973, 5427, 7629, 6532, 11083, 1581, 6666, 12006, 11021, 11369, 996, 6907, 11054, 8931, 6306, 534, 11019, 5927, 9760, 5624, 9161, 8358, 4261, 8412, 6837, 12516, 2841, 12152, 7938, 4040, 5904, 5701, 8823, 7031, 2838, 9229, 8526, 6081, 10116, 4192, 11637, 10855, 11365, 6984, 10431, 12255, 2361, 12486, 3571, 7643, 3751, 9146, 11620, 9339, 7132, 2780, 1059, 5809, 4432, 2103, 11109, 5319, 21, 6721, 6543, 4564, 3051, 720, 11310, 7007, 4811, 1656, 1588, 11617, 11213, 4448, 5012, 7550, 3168, 3945, 6446, 9052, 5914, 3321, 11266, 6684, 11923, 1221, 11661, 10842, 4963, 5708, 3825, 901, 5191, 6685, 12475, 7908, 9762, 7078, 11050, 8014, 143, 11443, 8323, 10180, 3697, 12124, 7354, 7805, 8714, 2223, 4524, 7175, 7981, 11720, 10922, 7410, 6442, 10956, 2048, 8351, 9018, 4348, 158, 1258, 7712, 12172, 12332, 8160, 4633, 12365, 10541, 2953, 6284, 4653, 6746, 5663, 3704, 3803, 1880, 6785, 2786, 730, 8641, 9967, 3896, 2153, 11526, 6372, 5436, 4821, 2268, 5463, 3245, 7408, 3308, 2656, 859, 12061, 11876, 3439, 2479, 6186, 3476, 2466, 8098, 12505, 10521, 3395, 1177, 1768, 11891, 3099, 3462, 10194, 2666, 6359, 6232, 9640, 8289, 10961, 8825, 9041, 4826, 11910, 4206, 3833, 6316, 5789, 11326, 2719, 2085, 3276, 6124, 87, 9807, 5562, 3386, 4317, 2350, 4030, 10688, 7244, 4819, 8648, 2420, 1343, 3963, 9174, 9736, 94, 10645, 10960, 9725, 11430, 5109, 4550, 2147, 9977, 4556, 10414, 4264, 741, 1584, 12477, 8075, 9379, 6771, 3236, 5724, 4489, 12416, 10778, 6228, 6805, 2770, 8553, 3363, 7616, 6122, 4691, 3694, 487, 4025, 5697, 6483, 6736, 9081, 1712, 11657, 11146, 8120, 4777, 1529, 2150, 11104, 2390, 6506, 10298, 12499, 6052, 12093, 1420, 6217, 9105, 8244, 4406, 7597, 3931, 4354, 1108, 8938, 8156, 6287, 2107, 2588, 4167, 9284, 7743, 3668, 9796, 4051, 9389, 788, 10517, 127, 5695, 12107, 10219, 6373, 8367, 337, 597, 4721, 8751, 609, 8651, 12517, 559, 5184, 1491, 7821, 2514, 12356, 1605, 5906, 7949, 6573, 9926, 12589, 6384, 232, 7028, 6401, 7306, 12483, 2650, 12252, 11523, 12131, 6941, 11776, 5651, 9961, 9922, 7279, 7507, 2630, 5802, 276, 7425, 8103, 7184, 2583, 2041, 1204, 5214, 12478, 5232, 6026, 4744, 5216, 5813, 2357, 10639, 7636, 2620, 1145, 218, 947, 548, 8021, 10052, 8159, 5547, 7525, 10056, 5150, 394, 8205, 9313, 11197, 3159, 2701, 9454, 11856, 5523, 1461, 10295, 4372, 2889, 5596, 3155, 5978, 11165, 12284, 606, 3946, 4967, 9182, 12208, 5294, 4456, 5660, 10338, 7562, 11422, 3544, 7319, 9658, 9777, 3344, 3757, 1137, 2677, 5148, 2673, 3585, 11591, 9129, 7858, 9296, 1513, 3144, 1729, 3331, 4280, 8697, 10700, 12487, 1285, 11481, 2566, 6421, 11252, 2785, 9498, 1711, 10490, 2892, 4602, 5348, 9981, 2161, 1161, 6639, 3283, 2811, 8710, 1833, 9028, 8333, 3041, 6862, 2729, 2943, 3319, 11503, 3369, 745, 4523, 8486, 10676, 7269, 10714, 4901, 6009, 5558, 9263, 10062, 10636, 7729, 847, 438, 3991, 12514, 8925, 2174, 10662, 9087, 6205, 283, 10529, 11942, 6028, 167, 12100, 12446, 11652, 3, 12304, 8901, 11801, 8954, 10477, 6015, 5149, 7228, 6920, 12386, 9429, 9225, 9247, 9500, 7725, 4693, 11588, 7812, 11707, 8728, 9720, 4384, 6157, 11134, 1220, 1228, 3994, 3453, 6680, 5186, 3675, 7165, 5603, 11572, 4748, 9095, 12344, 6439, 1707, 5033, 10440, 11577, 7146, 4700, 9060, 747, 2941, 513, 5212, 11752, 7023, 5475, 3621, 12297, 10096, 11339, 1191, 12614, 10625, 6403, 767, 9508, 5200, 7849, 9821, 9472, 1308, 7529, 1356, 10456, 1864, 1005, 12606, 779, 2035, 9634, 3798, 10875, 6325, 12380, 8145, 924, 3698, 9665, 7423, 5058, 3966, 8195, 11536, 5986, 4868, 8782, 6076, 5590, 2490, 349, 7336, 10971, 260, 2840, 5525, 2643, 2057, 6625, 10371, 1165, 3435, 8363, 8465, 7674, 10258, 1667, 5876, 11902, 2865, 3012, 11914, 3795, 807, 9706, 7056, 2906, 4604, 7622, 2135, 12119, 3821, 11217, 10873, 9668, 10537, 7572, 255, 1593, 1890, 821, 5205, 794, 8790, 8080, 9659, 11479, 2555, 11719, 9763, 5775, 3421, 9804, 8942, 8701, 8613, 12128, 8565, 456, 331, 7570, 10906, 4565, 3676, 10955, 4373, 3064, 8413, 7676, 7789, 6910, 5941, 11173, 4682, 1195, 4048, 11333, 5640, 6833, 8766, 5223, 5676, 6683, 3179, 12549, 948, 10693, 1820, 4164, 8863, 6048, 8177, 5961, 10949, 7612, 299, 402, 9093, 7851, 6031, 1144, 8343, 4267, 219, 6257, 5469, 3465, 1010, 7991, 5531, 10770, 1339]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_loader = get_train_data_loader(64)"
      ],
      "metadata": {
        "id": "KXXC8d37DfG4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the model using transfer learning"
      ],
      "metadata": {
        "id": "wzJ5yVksa_T1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First I'm gonna try my own CNN since AlexNet was trained on 224x224 and our images are a lot smaller (not sure if this matters)"
      ],
      "metadata": {
        "id": "y-F6G81ld7Ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrafficSignModel(nn.Module):\n",
        "  def __init__(self):\n",
        "     super(TrafficSignModel, self).__init__()\n",
        "     self.name = \"TrafficSignModel\"\n",
        "     self.conv1 = nn.Conv2d(3, 5, 5) # 3 input channels, 5 output channels, kernel size of 5\n",
        "     self.pool = nn.MaxPool2d(2, 2) # kernel size of 2, stride of 2\n",
        "     self.conv2 = nn.Conv2d(5, 10, 5) # 5 input channels, 10 output channels, kernel size of 5\n",
        "     self.fc1 = nn.Linear(10 * 9 * 9, 28) # 10 input channels, 12*12 input dimension, output to 28 channels\n",
        "     self.fc2 = nn.Linear(28, 43) # 28 channels to 43 channels for classification\n",
        "         \n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 10 * 9 * 9) # Flatten image\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    x = x.squeeze(1) # Flatten to [batch_size]\n",
        "    return x"
      ],
      "metadata": {
        "id": "ddDR2-8gbFQO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the network"
      ],
      "metadata": {
        "id": "P1nKIQ3sj3Gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Overview\n",
        "classes = { 0:'Speed limit (20km/h)',\n",
        "            1:'Speed limit (30km/h)', \n",
        "            2:'Speed limit (50km/h)', \n",
        "            3:'Speed limit (60km/h)', \n",
        "            4:'Speed limit (70km/h)', \n",
        "            5:'Speed limit (80km/h)', \n",
        "            6:'End of speed limit (80km/h)', \n",
        "            7:'Speed limit (100km/h)', \n",
        "            8:'Speed limit (120km/h)', \n",
        "            9:'No passing', \n",
        "            10:'No passing veh over 3.5 tons', \n",
        "            11:'Right-of-way at intersection', \n",
        "            12:'Priority road', \n",
        "            13:'Yield', \n",
        "            14:'Stop', \n",
        "            15:'No vehicles', \n",
        "            16:'Veh > 3.5 tons prohibited', \n",
        "            17:'No entry', \n",
        "            18:'General caution', \n",
        "            19:'Dangerous curve left', \n",
        "            20:'Dangerous curve right', \n",
        "            21:'Double curve', \n",
        "            22:'Bumpy road', \n",
        "            23:'Slippery road', \n",
        "            24:'Road narrows on the right', \n",
        "            25:'Road work', \n",
        "            26:'Traffic signals', \n",
        "            27:'Pedestrians', \n",
        "            28:'Children crossing', \n",
        "            29:'Bicycles crossing', \n",
        "            30:'Beware of ice/snow',\n",
        "            31:'Wild animals crossing', \n",
        "            32:'End speed + passing limits', \n",
        "            33:'Turn right ahead', \n",
        "            34:'Turn left ahead', \n",
        "            35:'Ahead only', \n",
        "            36:'Go straight or right', \n",
        "            37:'Go straight or left', \n",
        "            38:'Keep right', \n",
        "            39:'Keep left', \n",
        "            40:'Roundabout mandatory', \n",
        "            41:'End of no passing', \n",
        "            42:'End no passing veh > 3.5 tons' }"
      ],
      "metadata": {
        "id": "tXX00XOmkLPq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to obtain accuracy\n",
        "def get_accuracy(net, data_loader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for imgs, labels in data_loader:\n",
        "    #############################################\n",
        "    #To Enable GPU Usage\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "      imgs = imgs.cuda()\n",
        "      labels = labels.cuda()\n",
        "    #############################################\n",
        "    output = net(imgs)\n",
        "    prediction = output.max(1, keepdim=True)[1]\n",
        "    correct += prediction.eq(labels.view_as(prediction)).sum().item()\n",
        "    total += imgs.shape[0]\n",
        "  return correct / total"
      ],
      "metadata": {
        "id": "F5r5Pur9m5Jw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to obtain error\n",
        "def get_error(net, data_loader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  evaluate_net = net.eval()\n",
        "\n",
        "  for imgs, labels in data_loader:\n",
        "    #############################################\n",
        "    #To Enable GPU Usage\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "      imgs = imgs.cuda()\n",
        "      labels = labels.cuda()\n",
        "    #############################################\n",
        "    output = evaluate_net(imgs)\n",
        "    prediction = output.max(1, keepdim=True)[1]\n",
        "    correct += prediction.eq(labels.view_as(prediction)).sum().item()\n",
        "    total += imgs.shape[0]\n",
        "  return (total - correct) / total"
      ],
      "metadata": {
        "id": "I8Yh0Fs51Y-z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to obtain loss\n",
        "def get_loss(net, data_loader, criterion):\n",
        "  loss = 0.0\n",
        "  total_loss = 0.0\n",
        "  evaluate_net = net.eval()\n",
        "  for imgs, labels in data_loader:\n",
        "    #############################################\n",
        "    #To Enable GPU Usage\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "      imgs = imgs.cuda()\n",
        "      labels = labels.cuda()\n",
        "    #############################################\n",
        "    output = evaluate_net(imgs)\n",
        "    loss = criterion(output, labels)\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  loss = float(total_loss) / (len(data_loader))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "h1CAN_2B2BPt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get model name\n",
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch)\n",
        "    return path"
      ],
      "metadata": {
        "id": "an92DWly4Fbn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot Training Curve\n",
        "def plot_training_curve(path):\n",
        "    \"\"\" Plots the training curve for a model run, given the csv files\n",
        "    containing the train/validation error/loss.\n",
        "\n",
        "    Args:\n",
        "        path: The base path of the csv files produced during training\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    train_err = np.loadtxt(\"{}_train_err.csv\".format(path))\n",
        "    val_err = np.loadtxt(\"{}_val_err.csv\".format(path))\n",
        "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
        "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
        "    plt.title(\"Train vs Validation Error\")\n",
        "    n = len(train_err) # number of epochs\n",
        "    plt.plot(range(1,n+1), train_err, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_err, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Error\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    plt.title(\"Train vs Validation Loss\")\n",
        "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "de6ENbpS5sTJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_net(net, train_loader, val_loader, batch_size=64, learning_rate=0.01, num_epochs=30):\n",
        "  # Set the seed for reproducible results\n",
        "  torch.manual_seed(1000)\n",
        "\n",
        "  # Define the loss function - we will use Cross Entropy Loss for this classification problem\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  # Define the optimizer -  we will use Adaptive moment estimation\n",
        "  optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
        "\n",
        "  # Arrays to store stats\n",
        "  train_err = np.zeros(num_epochs)\n",
        "  train_loss = np.zeros(num_epochs)\n",
        "  val_err = np.zeros(num_epochs)\n",
        "  val_loss = np.zeros(num_epochs)\n",
        "\n",
        "  n = 0 # number iterations\n",
        "  for epoch in range(num_epochs):\n",
        "    total_train_loss = 0.0\n",
        "    for imgs, labels in train_loader:\n",
        "      #############################################\n",
        "      #To Enable GPU Usage\n",
        "      if use_cuda and torch.cuda.is_available():\n",
        "          imgs = imgs.cuda()\n",
        "          labels = labels.cuda()\n",
        "      #############################################\n",
        "      out = net(imgs)                 # forward passs\n",
        "      loss = criterion(out, labels)   # compute loss\n",
        "      loss.backward()                 # backward pass\n",
        "      optimizer.step()                # update paramters\n",
        "      optimizer.zero_grad()           # clean up\n",
        "\n",
        "      total_train_loss += loss.item()\n",
        "\n",
        "    train_err[epoch] = get_error(net, train_loader)\n",
        "    train_loss[epoch] = float(total_train_loss) / (len(train_loader))\n",
        "    val_err[epoch] = get_error(net, val_loader)\n",
        "    val_loss[epoch] = get_loss(net, val_loader, criterion)\n",
        "\n",
        "    print((\"Epoch {}: Train error: {}, Train loss: {}, Val error: {}, Val loss: {}\").format(\n",
        "        epoch +1,\n",
        "        train_err[epoch],\n",
        "        train_loss[epoch],\n",
        "        val_err[epoch],\n",
        "        val_loss[epoch]))\n",
        "    \n",
        "    # Save the current model after each epoch\n",
        "    model_path = get_model_name(net.name, batch_size, learning_rate, epoch)\n",
        "    torch.save(net.state_dict(), model_path)\n",
        "\n",
        "  # Finished training, save statistics to CSV\n",
        "  epochs = np.arange(1, num_epochs + 1)\n",
        "  np.savetxt(\"{}_train_err.csv\".format(model_path), train_err)\n",
        "  np.savetxt(\"{}_train_loss.csv\".format(model_path), val_err)\n",
        "  np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss)\n",
        "\n",
        "  # plotting\n",
        "  plot_training_curve(model_path)\n"
      ],
      "metadata": {
        "id": "yat0s7Q-j4kU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to overfit the data"
      ],
      "metadata": {
        "id": "6uM24qE2sBI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_debug_loader():\n",
        "  # Rescale images to all be the same size\n",
        "  data_transform = transforms.Compose([transforms.Resize((50,50)), \n",
        "                                       transforms.ToTensor()])\n",
        "\n",
        "  # Get paths to data in folder\n",
        "  debug_data = datasets.GTSRB('data', download=True, split=\"train\",\n",
        "                        transform=data_transform)\n",
        "  #print(len(debug_data))\n",
        "  debug_data = list(debug_data)\n",
        "  debug_data = debug_data[:64]\n",
        "  #print(len(debug_data))\n",
        "\n",
        "  np.random.seed(1000)\n",
        "  debug_loader = torch.utils.data.DataLoader(debug_data, batch_size=64,\n",
        "        num_workers=0, shuffle=True)\n",
        "  return debug_loader\n"
      ],
      "metadata": {
        "id": "kyG-_XD0sDVJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overfit_loader = get_debug_loader()\n",
        "model = TrafficSignModel()\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')\n",
        "\n",
        "train_net(model, train_loader, val_loader, batch_size=64, learning_rate=0.01, num_epochs=30)"
      ],
      "metadata": {
        "id": "DQVFjMfJy1Pw",
        "outputId": "bba081c7-c4f7-4671-af5d-69a664922308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n",
            "Epoch 1: Train error: 0.9436936936936937, Train loss: 3.5150042352058906, Val error: 0.9405166553365057, Val loss: 3.484541784162107\n",
            "Epoch 2: Train error: 0.9436936936936937, Train loss: 3.50373770750398, Val error: 0.9405166553365057, Val loss: 3.469381947448288\n",
            "Epoch 3: Train error: 0.9436936936936937, Train loss: 3.5018021717345973, Val error: 0.9405166553365057, Val loss: 3.4644983609517417\n",
            "Epoch 4: Train error: 0.9436936936936937, Train loss: 3.5018727407752754, Val error: 0.9430092907319284, Val loss: 3.4646257714948794\n",
            "Epoch 5: Train error: 0.9436936936936937, Train loss: 3.500799386049632, Val error: 0.9405166553365057, Val loss: 3.4643564742544424\n",
            "Epoch 6: Train error: 0.9436936936936937, Train loss: 3.5016622943557993, Val error: 0.9405166553365057, Val loss: 3.4647792543190112\n",
            "Epoch 7: Train error: 0.9459459459459459, Train loss: 3.50054166642882, Val error: 0.9430092907319284, Val loss: 3.4763960907424707\n",
            "Epoch 8: Train error: 0.9436936936936937, Train loss: 3.500674344938722, Val error: 0.9430092907319284, Val loss: 3.4652146705682725\n",
            "Epoch 9: Train error: 0.9436936936936937, Train loss: 3.500450086822327, Val error: 0.9405166553365057, Val loss: 3.464500370232955\n",
            "Epoch 10: Train error: 0.9436936936936937, Train loss: 3.5002126510766485, Val error: 0.9430092907319284, Val loss: 3.4640969556310903\n",
            "Epoch 11: Train error: 0.9459459459459459, Train loss: 3.500152153362759, Val error: 0.9430092907319284, Val loss: 3.4639879119568975\n",
            "Epoch 12: Train error: 0.9436936936936937, Train loss: 3.5003634779859216, Val error: 0.9430092907319284, Val loss: 3.4634797763133394\n",
            "Epoch 13: Train error: 0.9459459459459459, Train loss: 3.4994946560985465, Val error: 0.9430092907319284, Val loss: 3.4650321991547295\n",
            "Epoch 14: Train error: 0.9459459459459459, Train loss: 3.4999041946100102, Val error: 0.9430092907319284, Val loss: 3.464420904283938\n",
            "Epoch 15: Train error: 0.9436936936936937, Train loss: 3.5001643761742316, Val error: 0.9430092907319284, Val loss: 3.463752055513686\n",
            "Epoch 16: Train error: 0.9436936936936937, Train loss: 3.5005613877047166, Val error: 0.9405166553365057, Val loss: 3.4637678792511206\n",
            "Epoch 17: Train error: 0.9436936936936937, Train loss: 3.499370229615868, Val error: 0.9430092907319284, Val loss: 3.463262328203174\n",
            "Epoch 18: Train error: 0.9436936936936937, Train loss: 3.4994274100525486, Val error: 0.9405166553365057, Val loss: 3.4634052549583325\n",
            "Epoch 19: Train error: 0.9436936936936937, Train loss: 3.49946613220288, Val error: 0.9430092907319284, Val loss: 3.464459023613861\n",
            "Epoch 20: Train error: 0.9436936936936937, Train loss: 3.499906435287256, Val error: 0.9405166553365057, Val loss: 3.4635747722957446\n",
            "Epoch 21: Train error: 0.9459459459459459, Train loss: 3.499613254190349, Val error: 0.9430092907319284, Val loss: 3.4639562368392944\n",
            "Epoch 22: Train error: 0.9436936936936937, Train loss: 3.4997796520626516, Val error: 0.9430092907319284, Val loss: 3.4630278746287027\n",
            "Epoch 23: Train error: 0.9436936936936937, Train loss: 3.4995625310664553, Val error: 0.9430092907319284, Val loss: 3.463961209076038\n",
            "Epoch 24: Train error: 0.9436936936936937, Train loss: 3.4998269852974433, Val error: 0.9430092907319284, Val loss: 3.4640141811923706\n",
            "Epoch 25: Train error: 0.9436936936936937, Train loss: 3.4995196974820657, Val error: 0.9405166553365057, Val loss: 3.462864205457162\n",
            "Epoch 26: Train error: 0.9436936936936937, Train loss: 3.4999034130315985, Val error: 0.9405166553365057, Val loss: 3.463441705358201\n",
            "Epoch 27: Train error: 0.9436936936936937, Train loss: 3.4993503636879315, Val error: 0.9430092907319284, Val loss: 3.4642754274865855\n",
            "Epoch 28: Train error: 0.9436936936936937, Train loss: 3.4993858457469256, Val error: 0.9430092907319284, Val loss: 3.4647127683611885\n",
            "Epoch 29: Train error: 0.9436936936936937, Train loss: 3.499878623216844, Val error: 0.9405166553365057, Val loss: 3.4631852205248848\n",
            "Epoch 30: Train error: 0.9436936936936937, Train loss: 3.499368000945313, Val error: 0.9405166553365057, Val loss: 3.4636460732722627\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a3e2b5bb5746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CUDA is not available.  Training on CPU ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-4acaa9ffa0ab>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(net, train_loader, val_loader, batch_size, learning_rate, num_epochs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;31m# Finished training, save statistics to CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m   \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}_train_err.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}_train_loss.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0;32m--> 314\u001b[0;31m                                  \"{!r}\".format(__name__, attr))\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'arrange'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jordan just playing around to try to get a dataloader object\n",
        "I'm using Lab 2 as a guide"
      ],
      "metadata": {
        "id": "RglKHhQ0EC1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figuring out the structure of the dataset"
      ],
      "metadata": {
        "id": "0gTPskEHI89Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(gtsrb_data))\n",
        "print(gtsrb_data)\n",
        "print(len(gtsrb_data))\n",
        "print(gtsrb_data[10000][1])"
      ],
      "metadata": {
        "id": "_8iq5EPABv2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using some helper functions that I've slightly modified from Lab 2"
      ],
      "metadata": {
        "id": "MM_1SnduI_lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relevant_indices(dataset, classes, target_classes):\n",
        "    \"\"\" Return the indices for datapoints in the dataset that belongs to the\n",
        "    desired target classes, a subset of all possible classes.\n",
        "\n",
        "    Args:\n",
        "        dataset: Dataset object\n",
        "        classes: A list of strings denoting the name of each class\n",
        "        target_classes: A list of strings denoting the name of desired classes\n",
        "                        Should be a subset of the 'classes'\n",
        "    Returns:\n",
        "        indices: list of indices that have labels corresponding to one of the\n",
        "                 target classes\n",
        "    \"\"\"\n",
        "    indices = []\n",
        "    for i in range(len(dataset)):\n",
        "        # Check if the label is in the target classes\n",
        "        label_index = dataset[i][1] # ex: 3\n",
        "        # label_class = classes[label_index] # ex: 'cat'\n",
        "        if label_index in target_classes:\n",
        "            indices.append(i)\n",
        "    return indices\n",
        "\n",
        "def get_data_loader(target_classes, batch_size):\n",
        "    \"\"\" Loads images of signs, splits the data into training, validation\n",
        "    and testing datasets. Returns data loaders for the three preprocessed datasets.\n",
        "\n",
        "    Args:\n",
        "        target_classes: A list of ints denoting the index of the desired\n",
        "                        classes. Should be a subset of the argument 'classes'\n",
        "        batch_size: A int representing the number of samples per batch\n",
        "    \n",
        "    Returns:\n",
        "        train_loader: iterable training dataset organized according to batch size\n",
        "        val_loader: iterable validation dataset organized according to batch size\n",
        "        test_loader: iterable testing dataset organized according to batch size\n",
        "        classes: A list of ints denoting the index of each class\n",
        "    \"\"\"\n",
        "\n",
        "    classes = tuple(range(0,43))\n",
        "    ########################################################################\n",
        "    # The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "    # We transform them to Tensors of normalized range [-1, 1].\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    # Load GTSRB training data\n",
        "    trainset = torchvision.datasets.GTSRB(root='./data', split='train', transform=transform, download=True)\n",
        "    # Get the list of indices to sample from\n",
        "    relevant_indices = get_relevant_indices(trainset, classes, target_classes)\n",
        "    \n",
        "    # Split into train and validation\n",
        "    np.random.seed(1000) # Fixed numpy random seed for reproducible shuffling\n",
        "    np.random.shuffle(relevant_indices)\n",
        "    split = int(len(relevant_indices) * 0.8) #split at 80%\n",
        "    \n",
        "    # split into training and validation indices\n",
        "    relevant_train_indices, relevant_val_indices = relevant_indices[:split], relevant_indices[split:]  \n",
        "    train_sampler = SubsetRandomSampler(relevant_train_indices)\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                               num_workers=1, sampler=train_sampler)\n",
        "    val_sampler = SubsetRandomSampler(relevant_val_indices)\n",
        "    val_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                              num_workers=1, sampler=val_sampler)\n",
        "    # Load GTSRB testing data\n",
        "    testset = torchvision.datasets.GTSRB(root='./data', split='test', transform=transform, download=True)\n",
        "    # Get the list of indices to sample from\n",
        "    relevant_test_indices = get_relevant_indices(testset, classes, target_classes)\n",
        "    test_sampler = SubsetRandomSampler(relevant_test_indices)\n",
        "    test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                             num_workers=1, sampler=test_sampler)\n",
        "    return train_loader, val_loader, test_loader, classes"
      ],
      "metadata": {
        "id": "PMcCU1TfEJ_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = tuple(range(0,43))\n",
        "target_classes = (0,)\n",
        "print(type(classes[0]))\n",
        "print(classes)\n",
        "indices_class_0 = get_relevant_indices(gtsrb_data, classes, target_classes)\n",
        "print(indices_class_0) # Now I have the indices in gtsrb_data of ClassId=0\n",
        "\n",
        "# Get data loaders for training, validation, and test sets (images are only of ClassId=0)\n",
        "train_loader, val_loader, test_loader, classes = get_data_loader(target_classes, batch_size=5)"
      ],
      "metadata": {
        "id": "6fhhJ_GRFEQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Playing around with data loaders I created above\n",
        "print(len(train_loader)) # There are 24 batches (5 images/batch) in the train loader -> This is 120 images which is 80% of 150!\n",
        "print(len(val_loader)) # There are 6 batches (5 images/batch) in the val loader -> This is 30 images which is 20% of 150\n",
        "print(len(test_loader)) # There are 12 batches (5 images/batch) in the test loader -> This is 60 images"
      ],
      "metadata": {
        "id": "SIr_MqG5P1Wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next I'll try to plot some of the images, just to see what we're working with\n",
        "\n",
        "I don't think this is working because the images are of different sizes, we'll have to figure out what we're doing about this."
      ],
      "metadata": {
        "id": "wyiDh_OrQg1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 0\n",
        "for images, labels in enumerate(train_loader):\n",
        "    # since batch_size = 5, there are 5 images in 'images'\n",
        "    for i in range(0,5):\n",
        "      image = images[i]\n",
        "      # place the colour channel at the end, instead of at the beginning\n",
        "      img = np.transpose(image, [1,2,0])\n",
        "      # normalize pixel intensity values to [0, 1]\n",
        "      img = img / 2 + 0.5\n",
        "      plt.subplot(3, 5, k+1)\n",
        "      plt.axis('off')\n",
        "      plt.imshow(img)\n",
        "\n",
        "    k += 1\n",
        "    if k > 14:\n",
        "        break"
      ],
      "metadata": {
        "id": "TbPtVo8hRhrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper Functions**\n",
        "\n",
        "Will need functions to\n",
        "\n",
        "\n",
        "*   Get model name (for training)\n",
        "*   Evaluate network on validation set\n",
        "*   Plot the training curves\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "egEbz8G-zjoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Model Architecture**"
      ],
      "metadata": {
        "id": "w_KzPXjrkPwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrafficSignModel(nn.Module):\n",
        "  def __init__(self):\n",
        "     super(TrafficSignModel, self).__init__()\n",
        "     self.name = \"TrafficSignModel\"\n",
        "     self.conv1 = nn.Conv2d(3, 5, 5) # 3 input channels, 5 output channels, kernel size of 5\n",
        "     self.pool = nn.MaxPool2d(2, 2), # kernel size of 2, stride of 2\n",
        "     self.conv2 = nn.Conv2d(5, 10, 5), # 5 input channels, 10 output channels, kernel size of 5\n",
        "     self.fc1 = nn.Linear() # Will need to figure out these dimensions (based on input dimensions of image - how are we handling this?)\n",
        "     self.fc2 = nn.Linear() # Will need to figure out these dimensions (based on how many different classes we are working with - do we know?)\n",
        "         \n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, ) # Will need to figure out these dimensions - see above\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    x = x.squeeze(1) # Flatten to [batch_size]\n",
        "    return x"
      ],
      "metadata": {
        "id": "4JOOPHI2e32S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**\n",
        "\n",
        "Function to train the neural network\n",
        "Need to decide loss function and optimizer\n",
        "\n",
        "A lot of this code can be adopted from the Labs and tutorials"
      ],
      "metadata": {
        "id": "vcKCZzFM0FNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Katherine trying to augment the data"
      ],
      "metadata": {
        "id": "hAcXNqEFygYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_datasets = []\n",
        "\n",
        "my_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(25),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "for _ in range(2):\n",
        "    gtsrb_new = datasets.GTSRB('data', download=True, transform=my_transform)\n",
        "    augmented_datasets.append(gtsrb_new)\n",
        "\n",
        "concat = torch.utils.data.ConcatDataset(augmented_datasets)"
      ],
      "metadata": {
        "id": "D2mlKZzVbOdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount our Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Y_Ww0BuCsn1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('drive/MyDrive/APS360/Project/SyRa-Synthesized_Rain_dataset-main')"
      ],
      "metadata": {
        "id": "xaDR2GM-28cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"assets/folder_of_your_data/folder_of_your_data/\")"
      ],
      "metadata": {
        "id": "rsz0Ia9VVsDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "vRoYScaKZkso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data = get_train_data_loader(img_size=256)\n",
        "\n",
        "for i, data in enumerate(train_data):\n",
        "  img, label = data\n",
        "  for j in range(img.shape[0]):\n",
        "      torchvision.utils.save_image(img[j,:,:,:], 'assets/folder_of_your_data/folder_of_your_data/{}{}.png'.format(i,j))\n",
        "  if i>=0:\n",
        "    break"
      ],
      "metadata": {
        "id": "frhsUX1aPbwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install munch"
      ],
      "metadata": {
        "id": "SpR5VVyBsmZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg"
      ],
      "metadata": {
        "id": "4XOInrzftQD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import munch\n",
        "import ffmpeg\n",
        "import os"
      ],
      "metadata": {
        "id": "r33Bjf_DstXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('drive/MyDrive/APS360/Project/SyRa-Synthesized_Rain_dataset-main')"
      ],
      "metadata": {
        "id": "-X-yAwXgs4fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "python main.py --img_size 256 --mode syn --checkpoint_dir expr/checkpoint/SyRa --out_dir expr/result --data folder_of_your_data --resume_iter 100000"
      ],
      "metadata": {
        "id": "cyGDEPOkz2lh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}